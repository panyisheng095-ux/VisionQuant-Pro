"""
ç”¨ AttentionCAE é‡å»º FAISS ç´¢å¼•

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„ AttentionCAE æ¨¡å‹
2. æ‰«ææ‰€æœ‰ K çº¿å›¾ï¼ˆ40ä¸‡å¼ ï¼‰
3. ç”¨æ–°æ¨¡å‹é‡æ–°ç¼–ç æ‰€æœ‰å›¾ç‰‡
4. æ„å»ºæ–°çš„ FAISS ç´¢å¼•

è¿è¡Œæ—¶é—´ï¼šçº¦ 1-2 å°æ—¶ï¼ˆå–å†³äº CPU/GPUï¼‰
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import faiss
import pandas as pd
import numpy as np
from tqdm import tqdm
from datetime import datetime
import glob

# === è·¯å¾„é…ç½® ===
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from src.models.attention_cae import AttentionCAE

# è¾“å…¥è¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤å€¼ï¼Œå¯è¢«å‘½ä»¤è¡Œè¦†ç›–ï¼‰
DEFAULT_IMG_BASE_DIR = os.path.join(PROJECT_ROOT, "data", "images")
MODEL_PATH = os.path.join(PROJECT_ROOT, "data", "models", "attention_cae_best.pth")
DEFAULT_INDEX_FILE = os.path.join(PROJECT_ROOT, "data", "indices", "cae_faiss_attention.bin")
DEFAULT_META_CSV = os.path.join(PROJECT_ROOT, "data", "indices", "meta_data_attention.csv")

parser = argparse.ArgumentParser(description="ç”¨ AttentionCAE é‡å»º FAISS ç´¢å¼•")
parser.add_argument("--img-dir", type=str, default=DEFAULT_IMG_BASE_DIR, help="Kçº¿å›¾ç›®å½•ï¼ˆé»˜è®¤ data/imagesï¼‰")
parser.add_argument("--index-file", type=str, default=DEFAULT_INDEX_FILE, help="è¾“å‡ºç´¢å¼•æ–‡ä»¶è·¯å¾„")
parser.add_argument("--meta-csv", type=str, default=DEFAULT_META_CSV, help="è¾“å‡ºå…ƒæ•°æ®CSVè·¯å¾„")
parser.add_argument("--batch-size", type=int, default=64, help="ç¼–ç æ‰¹å¤§å°ï¼ˆå»ºè®® 32-128ï¼‰")
args = parser.parse_args()

IMG_BASE_DIR = args.img_dir
INDEX_FILE = args.index_file
META_CSV = args.meta_csv

# è®¾å¤‡é€‰æ‹©
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("ğŸš€ ä½¿ç”¨ Apple MPS GPU åŠ é€Ÿ")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("ğŸš€ ä½¿ç”¨ CUDA GPU åŠ é€Ÿ")
else:
    device = torch.device("cpu")
    print("ğŸ’» ä½¿ç”¨ CPUï¼ˆè¾ƒæ…¢ï¼Œå»ºè®®ç”¨ GPUï¼‰")

# === 1. åŠ è½½æ¨¡å‹ ===
print("\n" + "="*60)
print("ğŸ“¦ æ­¥éª¤ 1: åŠ è½½ AttentionCAE æ¨¡å‹")
print("="*60)

model = AttentionCAE(latent_dim=1024, num_attention_heads=8).to(device)
if os.path.exists(MODEL_PATH):
    state_dict = torch.load(MODEL_PATH, map_location=device)
    model.load_state_dict(state_dict)
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {MODEL_PATH}")
else:
    print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")
    sys.exit(1)

# é¢„å¤„ç†
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# === 2. æ‰«ææ‰€æœ‰å›¾ç‰‡ ===
print("\n" + "="*60)
print("ğŸ“‚ æ­¥éª¤ 2: æ‰«æ K çº¿å›¾ç›®å½•")
print("="*60)

# æŸ¥æ‰¾æ‰€æœ‰ PNG æ–‡ä»¶
all_img_paths = glob.glob(os.path.join(IMG_BASE_DIR, "**", "*.png"), recursive=True)
all_img_paths.sort()
print(f"âœ… æ‰¾åˆ° {len(all_img_paths)} å¼ å›¾ç‰‡ (ç›®å½•: {IMG_BASE_DIR})")

if len(all_img_paths) == 0:
    print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„:", IMG_BASE_DIR)
    sys.exit(1)

# === 3. æå–ç‰¹å¾å‘é‡ ===
print("\n" + "="*60)
print("ğŸ” æ­¥éª¤ 3: ç”¨ AttentionCAE ç¼–ç æ‰€æœ‰å›¾ç‰‡å¹¶æ„å»ºç´¢å¼•")
print("="*60)
print("âš ï¸  è¿™å¯èƒ½éœ€è¦ 1-2 å°æ—¶ï¼Œè¯·è€å¿ƒç­‰å¾…...")

meta_list = []
batch_size = max(1, int(args.batch_size))
index = None
dim = None

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(os.path.dirname(INDEX_FILE), exist_ok=True)

with torch.no_grad():
    batch_tensors = []
    batch_meta = []
    for img_path in tqdm(all_img_paths, desc="ç¼–ç ä¸­"):
        try:
            # åŠ è½½å›¾ç‰‡
            with Image.open(img_path) as img:
                img = img.convert('RGB')
                input_tensor = preprocess(img)

            # ä»è·¯å¾„æå–è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸ
            # è·¯å¾„æ ¼å¼: data/images/600519/600519_20230101.png
            filename = os.path.basename(img_path)
            parts = filename.replace('.png', '').split('_')
            if len(parts) >= 2:
                symbol = parts[0].zfill(6)
                date_str = parts[1]
            else:
                # å¤‡ç”¨è§£æ
                symbol = os.path.basename(os.path.dirname(img_path)).zfill(6)
                date_str = filename.replace('.png', '')

            batch_tensors.append(input_tensor)
            batch_meta.append({
                'symbol': symbol,
                'date': date_str,
                'path': img_path
            })

            if len(batch_tensors) >= batch_size:
                input_batch = torch.stack(batch_tensors).to(device)
                features = model.encode(input_batch)
                features_np = features.cpu().numpy().astype('float32')

                if index is None:
                    dim = features_np.shape[1]
                    print(f"ç‰¹å¾ç»´åº¦: {dim} (åº”è¯¥æ˜¯ 1024)")
                    index = faiss.IndexFlatIP(dim)

                faiss.normalize_L2(features_np)
                index.add(features_np)
                meta_list.extend(batch_meta)
                batch_tensors.clear()
                batch_meta.clear()
        except Exception as e:
            print(f"\nâš ï¸  è·³è¿‡æŸåå›¾ç‰‡ {img_path}: {e}")
            continue

    if batch_tensors:
        input_batch = torch.stack(batch_tensors).to(device)
        features = model.encode(input_batch)
        features_np = features.cpu().numpy().astype('float32')

        if index is None:
            dim = features_np.shape[1]
            print(f"ç‰¹å¾ç»´åº¦: {dim} (åº”è¯¥æ˜¯ 1024)")
            index = faiss.IndexFlatIP(dim)

        faiss.normalize_L2(features_np)
        index.add(features_np)
        meta_list.extend(batch_meta)

if index is None or index.ntotal == 0:
    print("âŒ æ²¡æœ‰æˆåŠŸç¼–ç ä»»ä½•å›¾ç‰‡ï¼Œç´¢å¼•æ„å»ºå¤±è´¥")
    sys.exit(1)

print(f"\nâœ… ç¼–ç å®Œæˆï¼å…±å¤„ç† {index.ntotal} å¼ å›¾ç‰‡")
print(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼åŒ…å« {index.ntotal} æ¡è®°å½•")

# === 5. ä¿å­˜ç´¢å¼•å’Œå…ƒæ•°æ® ===
print("\n" + "="*60)
print("ğŸ’¾ æ­¥éª¤ 5: ä¿å­˜ç´¢å¼•å’Œå…ƒæ•°æ®")
print("="*60)

# ä¿å­˜ FAISS ç´¢å¼•
faiss.write_index(index, INDEX_FILE)
print(f"âœ… FAISS ç´¢å¼•å·²ä¿å­˜: {INDEX_FILE}")

# ä¿å­˜å…ƒæ•°æ® CSV
meta_df = pd.DataFrame(meta_list)
meta_df.to_csv(META_CSV, index=False)
print(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜: {META_CSV}")

# === 6. æ›´æ–° VisionEngine é…ç½® ===
print("\n" + "="*60)
print("ğŸ“ æ­¥éª¤ 6: æ›´æ–°é…ç½®")
print("="*60)
print("âœ… VisionEngine ä¼šä¼˜å…ˆåŠ è½½ attention ç´¢å¼•ï¼Œæ— éœ€æ‰‹åŠ¨æ”¹è·¯å¾„")
print("è‹¥éœ€å…¼å®¹æ—§ä»£ç ï¼Œå¯å¤‡ä»½åæ›¿æ¢é»˜è®¤ç´¢å¼•æ–‡ä»¶ï¼š")
print(f"   mv {INDEX_FILE} {os.path.join(PROJECT_ROOT, 'data', 'indices', 'cae_faiss.bin')}")
print(f"   mv {META_CSV} {os.path.join(PROJECT_ROOT, 'data', 'indices', 'meta_data.csv')}")

print("\n" + "="*60)
print("ğŸ‰ ç´¢å¼•é‡å»ºå®Œæˆï¼")
print("="*60)
print(f"æ€»è®°å½•æ•°: {index.ntotal}")
print(f"ç‰¹å¾ç»´åº¦: {dim}")
print(f"ç´¢å¼•æ–‡ä»¶: {INDEX_FILE}")
print(f"å…ƒæ•°æ®æ–‡ä»¶: {META_CSV}")
