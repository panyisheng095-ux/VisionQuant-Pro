"""
å¤šå°ºåº¦æ¨¡å‹è®­ç»ƒè„šæœ¬
Multi-Scale Model Training Script

è®­ç»ƒæ—¥çº¿/å‘¨çº¿/æœˆçº¿Kçº¿å›¾æ¨¡å‹

Author: VisionQuant Team
"""

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import pandas as pd
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from src.models.attention_cae import AttentionCAE
from src.data.multi_scale_generator import MultiScaleChartGenerator
from src.data.data_loader import DataLoader as StockDataLoader


class MultiScaleDataset(Dataset):
    """
    å¤šå°ºåº¦Kçº¿å›¾æ•°æ®é›†
    """
    
    def __init__(
        self,
        stock_list: list,
        data_loader: StockDataLoader,
        chart_generator: MultiScaleChartGenerator,
        scale: str = 'daily'  # 'daily', 'weekly', 'monthly'
    ):
        """
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            data_loader: æ•°æ®åŠ è½½å™¨
            chart_generator: Kçº¿å›¾ç”Ÿæˆå™¨
            scale: æ—¶é—´å°ºåº¦
        """
        self.stock_list = stock_list
        self.data_loader = data_loader
        self.chart_generator = chart_generator
        self.scale = scale
        
        # é¢„ç”Ÿæˆæ‰€æœ‰å›¾è¡¨ï¼ˆæˆ–æŒ‰éœ€ç”Ÿæˆï¼‰
        self.chart_paths = []
        self._prepare_data()
    
    def _prepare_data(self):
        """å‡†å¤‡æ•°æ®"""
        print(f"ğŸ“Š å‡†å¤‡{self.scale}å°ºåº¦æ•°æ®...")
        for symbol in tqdm(self.stock_list, desc="ç”Ÿæˆå›¾è¡¨"):
            try:
                df = self.data_loader.get_stock_data(symbol)
                if df.empty:
                    continue
                
                # ç”Ÿæˆå¯¹åº”å°ºåº¦çš„å›¾è¡¨
                if self.scale == 'daily':
                    chart_path = self.chart_generator.generate_daily_chart(df)
                elif self.scale == 'weekly':
                    chart_path = self.chart_generator.generate_weekly_chart(df)
                elif self.scale == 'monthly':
                    chart_path = self.chart_generator.generate_monthly_chart(df)
                else:
                    continue
                
                self.chart_paths.append({
                    'symbol': symbol,
                    'chart_path': chart_path
                })
            except Exception as e:
                print(f"âš ï¸ å¤„ç† {symbol} å¤±è´¥: {e}")
                continue
    
    def __len__(self):
        return len(self.chart_paths)
    
    def __getitem__(self, idx):
        from PIL import Image
        from torchvision import transforms
        
        item = self.chart_paths[idx]
        chart_path = item['chart_path']
        
        # åŠ è½½å›¾åƒ
        img = Image.open(chart_path).convert('RGB')
        
        # é¢„å¤„ç†
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor()
        ])
        
        img_tensor = transform(img)
        
        return img_tensor, item['symbol']


def train_multi_scale_model(
    scale: str = 'daily',
    latent_dim: int = 2048,
    batch_size: int = 32,
    epochs: int = 10,
    learning_rate: float = 1e-4,
    stock_list: list = None
):
    """
    è®­ç»ƒå¤šå°ºåº¦æ¨¡å‹
    
    Args:
        scale: æ—¶é—´å°ºåº¦ ('daily', 'weekly', 'monthly')
        latent_dim: ç‰¹å¾ç»´åº¦
        batch_size: æ‰¹æ¬¡å¤§å°
        epochs: è®­ç»ƒè½®æ•°
        learning_rate: å­¦ä¹ ç‡
        stock_list: è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨ï¼‰
    """
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ{scale}å°ºåº¦æ¨¡å‹...")
    print(f"   ç‰¹å¾ç»´åº¦: {latent_dim}")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   è®­ç»ƒè½®æ•°: {epochs}")
    
    # è®¾å¤‡
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("ğŸš€ ä½¿ç”¨ Apple MPS GPU åŠ é€Ÿ")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("ğŸš€ ä½¿ç”¨ CUDA GPU åŠ é€Ÿ")
    else:
        device = torch.device("cpu")
        print("ğŸ’» ä½¿ç”¨ CPU")
    
    # æ•°æ®åŠ è½½
    data_loader = StockDataLoader()
    chart_generator = MultiScaleChartGenerator()
    
    if stock_list is None:
        # ä½¿ç”¨é»˜è®¤è‚¡ç¥¨åˆ—è¡¨ï¼ˆTop 100ï¼‰
        top_stocks = data_loader.get_top300_stocks()
        stock_list = top_stocks['code'].head(100).tolist()
    
    # æ•°æ®é›†
    dataset = MultiScaleDataset(
        stock_list=stock_list,
        data_loader=data_loader,
        chart_generator=chart_generator,
        scale=scale
    )
    
    if len(dataset) == 0:
        print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒ")
        return
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4
    )
    
    # æ¨¡å‹
    model = AttentionCAE(
        latent_dim=latent_dim,
        feature_dim=512 if latent_dim >= 2048 else 256  # é«˜ç»´åº¦æ—¶å¢åŠ ç‰¹å¾é€šé“
    ).to(device)
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    criterion = nn.MSELoss()
    
    # è®­ç»ƒ
    model.train()
    for epoch in range(epochs):
        total_loss = 0.0
        progress_bar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
        
        for batch_idx, (images, symbols) in enumerate(progress_bar):
            images = images.to(device)
            
            # å‰å‘ä¼ æ’­
            recon, latent = model(images)
            
            # é‡å»ºæŸå¤±
            loss = criterion(recon, images)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {epoch+1}/{epochs}, å¹³å‡æŸå¤±: {avg_loss:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    model_dir = os.path.join(PROJECT_ROOT, "data", "models")
    os.makedirs(model_dir, exist_ok=True)
    
    model_path = os.path.join(
        model_dir,
        f"attention_cae_{scale}_{latent_dim}d.pth"
    )
    
    torch.save(model.state_dict(), model_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    return model_path


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='è®­ç»ƒå¤šå°ºåº¦Kçº¿å›¾æ¨¡å‹')
    parser.add_argument('--scale', type=str, default='daily', choices=['daily', 'weekly', 'monthly'])
    parser.add_argument('--latent_dim', type=int, default=2048, choices=[512, 1024, 2048])
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--lr', type=float, default=1e-4)
    
    args = parser.parse_args()
    
    train_multi_scale_model(
        scale=args.scale,
        latent_dim=args.latent_dim,
        batch_size=args.batch_size,
        epochs=args.epochs,
        learning_rate=args.lr
    )
