import akshare as ak
import pandas as pd
import numpy as np
import time
import os
import json
import difflib
from src.utils.net_utils import no_proxy_env

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class FundamentalMiner:
    def __init__(self, spot_cache_ttl_sec: int = 300, spot_retry: int = 2):
        # ç¼“å­˜å…¨å¸‚åœº spotï¼ˆak.stock_zh_a_spot_em å¾ˆé‡ï¼Œä¸”æ˜“æ³¢åŠ¨ï¼›ç¼“å­˜èƒ½æ˜¾è‘—é™ä½ N/Aï¼‰
        self._spot_cache_df = None
        self._spot_cache_ts = 0.0
        self._spot_cache_ttl_sec = spot_cache_ttl_sec
        self._spot_retry = spot_retry
        self._industry_cache = {}
        self._peers_cache = {}
        self._industry_map = {}
        self._industry_cons_cache = {}
        self._industry_map_ts = 0.0
        self._industry_map_ttl_sec = 24 * 3600
        self._industry_board_names = []
        self._industry_board_ts = 0.0
        self._industry_board_ttl_sec = 24 * 3600
        self._industry_name_cache = {}
        self._industry_cache_ts = 0.0
        self._industry_cache_ttl_sec = 7 * 24 * 3600
        self._industry_cache_path = os.path.join(PROJECT_ROOT, "data", "industry_cache.json")
        self._spot_cache_path = os.path.join(PROJECT_ROOT, "data", "spot_cache.csv")
        self._load_industry_cache()
        self._load_spot_cache()

    def _load_industry_cache(self):
        try:
            if os.path.exists(self._industry_cache_path):
                with open(self._industry_cache_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                cache_map = data.get("map", {})
                ts = data.get("ts", 0.0)
                if isinstance(cache_map, dict):
                    self._industry_cache.update(cache_map)
                self._industry_cache_ts = float(ts) if ts else 0.0
        except Exception:
            pass

    def _save_industry_cache(self):
        try:
            os.makedirs(os.path.dirname(self._industry_cache_path), exist_ok=True)
            payload = {"ts": time.time(), "map": self._industry_cache}
            with open(self._industry_cache_path, "w", encoding="utf-8") as f:
                json.dump(payload, f, ensure_ascii=False)
        except Exception:
            pass

    def _load_spot_cache(self):
        try:
            if os.path.exists(self._spot_cache_path):
                df = pd.read_csv(self._spot_cache_path)
                if df is not None and not df.empty:
                    # æ ‡å‡†åŒ–ä»£ç åˆ—
                    code_col = next((c for c in df.columns if 'ä»£ç ' in c or 'code' in str(c).lower()), None)
                    if code_col:
                        df[code_col] = df[code_col].astype(str).str.zfill(6)
                    self._spot_cache_df = df
                    self._spot_cache_ts = time.time()
        except Exception:
            pass

    def _save_spot_cache(self, df: pd.DataFrame):
        try:
            if df is None or df.empty:
                return
            os.makedirs(os.path.dirname(self._spot_cache_path), exist_ok=True)
            df.to_csv(self._spot_cache_path, index=False)
        except Exception:
            pass

    def get_stock_fundamentals(self, symbol, force_live: bool = False):
        """
        è·å–æ·±åº¦è´¢åŠ¡æŒ‡æ ‡ (å«æˆé•¿æ€§ä¸å®‰å…¨æ€§åˆ†æ)
        """
        symbol = str(symbol).strip().zfill(6)
        print(f"ğŸ” [è´¢åŠ¡åˆ†æ] æ­£åœ¨é€è§† {symbol}...")

        # é»˜è®¤ç»“æœç»“æ„æ‰©å±•
        result = {
            "symbol": symbol,
            # é»˜è®¤ä¸è¦ç”¨ symbol å½“ nameï¼Œå¦åˆ™ UI ä¼šå‡ºç° â€œ300286(300286)â€ è¿™ç§é‡å¤ä¸”æ©ç›–æŠ“å–å¤±è´¥
            "name": "",
            "industry": "",
            "pe_ttm": 0.0, "pb": 0.0, "total_mv": 0.0,
            "net_profit": 0.0,
            "roe": 0.0, "net_profit_margin": 0.0, "asset_turnover": 0.6, "leverage": 1.0,
            "debt_asset_ratio": 0.0,
            # === æ–°å¢æŒ‡æ ‡ ===
            "gross_margin": 0.0,  # æ¯›åˆ©ç‡
            "current_ratio": 0.0,  # æµåŠ¨æ¯”ç‡ (å¿å€ºèƒ½åŠ›)
            "rev_growth": 0.0,  # è¥æ”¶å¢é•¿ç‡
            "profit_growth": 0.0,  # å‡€åˆ©å¢é•¿ç‡
            "report_date": "æœ€æ–°"
            ,
            # === çŠ¶æ€å­—æ®µï¼šç”¨äºUIå±‚åˆ¤æ–­â€œæ˜¯å¦æˆåŠŸæŠ“å–â€ï¼Œé¿å…æŠŠ0å½“çœŸ ===
            "_ok": {"spot": False, "finance": False},
            "_err": []
        }

        def _fill_from_spot(spot_df: pd.DataFrame) -> bool:
            try:
                if spot_df is None or spot_df.empty:
                    return False
                code_col = next((c for c in spot_df.columns if 'ä»£ç ' in c or 'code' in str(c).lower()), None)
                if not code_col:
                    return False
                spot_df = spot_df.copy()
                spot_df[code_col] = spot_df[code_col].astype(str).str.zfill(6)
                target = spot_df[spot_df[code_col] == symbol]
                if target.empty:
                    return False

                def _pick_col(cols, keywords, prefer=None):
                    prefer = prefer or []
                    prefer_groups = []
                    for p in prefer:
                        if isinstance(p, (list, tuple, set)):
                            prefer_groups.append([str(x) for x in p])
                        else:
                            prefer_groups.append([str(p)])
                    for c in cols:
                        for group in prefer_groups:
                            if group and all(k in str(c) for k in group):
                                return c
                    for c in cols:
                        if any(k in str(c) for k in keywords):
                            return c
                    return None

                cols = list(target.columns)
                pe_col = _pick_col(
                    cols,
                    ["å¸‚ç›ˆç‡", "PE", "pe", "TTM", "æ»šåŠ¨", "åŠ¨æ€"],
                    prefer=[["å¸‚ç›ˆç‡", "TTM"], ["å¸‚ç›ˆç‡", "åŠ¨"], ["PE", "TTM"]]
                )
                pb_col = _pick_col(cols, ["å¸‚å‡€ç‡", "PB", "pb", "å¸‚å¸ç‡", "P/B"])
                mv_col = _pick_col(cols, ["æ€»å¸‚å€¼", "å¸‚å€¼", "market", "MV"])
                name_col = next((c for c in target.columns if 'åç§°' in c), None)
                ind_col = next((c for c in target.columns if 'è¡Œä¸š' in c), None)

                updated = False
                if pe_col:
                    pe_val = self._to_f(target[pe_col].values[0])
                    if self._is_valid_num(pe_val):
                        result["pe_ttm"] = pe_val
                        updated = True
                if pb_col:
                    pb_val = self._to_f(target[pb_col].values[0])
                    if self._is_valid_num(pb_val):
                        result["pb"] = pb_val
                        updated = True
                if mv_col:
                    mv_val = self._to_f(target[mv_col].values[0])
                    if self._is_valid_num(mv_val):
                        result["total_mv"] = round(mv_val / 100000000, 2)
                        updated = True
                if name_col and not result.get("name"):
                    result["name"] = str(target[name_col].values[0]).strip()
                if ind_col and not result.get("industry"):
                    ind_val = str(target[ind_col].values[0]).strip()
                    if ind_val and ind_val not in ["æœªçŸ¥", "-"]:
                        result["industry"] = ind_val

                if updated:
                    result["_ok"]["spot"] = True
                return updated
            except Exception as e:
                result["_err"].append(f"spot_df_parse_error: {type(e).__name__}: {e}")
                return False

        try:
            # 1. å®æ—¶ä¼°å€¼
            try:
                spot_df = self._get_spot_df_live(result) if force_live else self._get_spot_df_cached(result)
                ok = _fill_from_spot(spot_df)
                # è‹¥æœªæ‹¿åˆ°æœ‰æ•ˆä¼°å€¼ï¼Œå¼ºåˆ¶åˆ·æ–°ä¸€æ¬¡
                if not ok and (result.get("pe_ttm", 0) == 0 and result.get("pb", 0) == 0):
                    spot_df = self._get_spot_df_live(result) if force_live else self._get_spot_df_cached(result, force_refresh=True)
                    _fill_from_spot(spot_df)
            except Exception as e:
                result["_err"].append(f"spot_df_error: {type(e).__name__}: {e}")

            # è‹¥ spot æœªæ‹¿åˆ° name æˆ– PE/PBï¼Œå°è¯•æ›´è½»é‡çš„ä¸ªè‚¡ä¿¡æ¯æ¥å£å…œåº•ï¼ˆå¸¦é‡è¯•ï¼‰
            if not result.get("name") or (result.get("pe_ttm", 0) == 0 and result.get("pb", 0) == 0):
                for attempt in range(max(1, self._spot_retry + 1)):
                    try:
                        with no_proxy_env():
                            info_df = ak.stock_individual_info_em(symbol=symbol)
                        if info_df is not None and not info_df.empty:
                            # å¸¸è§å­—æ®µï¼šitem/value
                            if "item" in info_df.columns and "value" in info_df.columns:
                                # è·å–è‚¡ç¥¨åç§°
                                if not result.get("name"):
                                    name_row = info_df[info_df["item"].astype(str).str.contains("è‚¡ç¥¨ç®€ç§°|åç§°")]
                                    if not name_row.empty:
                                        result["name"] = str(name_row["value"].values[0]).strip()

                                # è·å–è¡Œä¸šä¿¡æ¯ï¼ˆç”¨äºåç»­è¡Œä¸šå¯¹æ ‡ï¼Œå‡å°‘é‡å¤è¯·æ±‚ï¼‰
                                try:
                                    ind_row = info_df[info_df["item"].astype(str).str.contains("è¡Œä¸š|æ‰€å±è¡Œä¸š")]
                                    if not ind_row.empty:
                                        industry_val = str(ind_row["value"].values[0]).strip()
                                        if industry_val and industry_val not in ["æœªçŸ¥", ""]:
                                            result["industry"] = industry_val
                                            self._industry_cache[symbol] = industry_val
                                            if not force_live:
                                                self._save_industry_cache()
                                except Exception:
                                    pass
                                
                                # å°è¯•è·å–PE/PBï¼ˆå¦‚æœspot_dfæ²¡æœ‰è·å–åˆ°ï¼‰
                                if result.get("pe_ttm", 0) == 0:
                                    pe_row = info_df[info_df["item"].astype(str).str.contains(
                                        "å¸‚ç›ˆç‡|PE|æ»šåŠ¨å¸‚ç›ˆç‡|TTM|åŠ¨æ€å¸‚ç›ˆç‡", case=False, regex=True
                                    )]
                                    if not pe_row.empty:
                                        result["pe_ttm"] = self._to_f(pe_row["value"].values[0])
                                
                                if result.get("pb", 0) == 0:
                                    pb_row = info_df[info_df["item"].astype(str).str.contains(
                                        "å¸‚å‡€ç‡|PB|P/B", case=False, regex=True
                                    )]
                                    if not pb_row.empty:
                                        result["pb"] = self._to_f(pb_row["value"].values[0])

                                if result.get("total_mv", 0) == 0:
                                    mv_row = info_df[info_df["item"].astype(str).str.contains(
                                        "æ€»å¸‚å€¼|å¸‚å€¼", case=False, regex=True
                                    )]
                                    if not mv_row.empty:
                                        result["total_mv"] = round(self._to_f(mv_row["value"].values[0]) / 100000000, 2)
                                
                                # å¦‚æœè·å–åˆ°å…³é”®æ•°æ®ï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                                if result.get("name") or self._is_valid_num(result.get("pe_ttm", 0)):
                                    break
                        if attempt < self._spot_retry:
                            time.sleep(0.5 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                    except Exception as e:
                        if attempt < self._spot_retry:
                            time.sleep(0.5 * (attempt + 1))
                            continue
                        result["_err"].append(f"stock_individual_info_error: {type(e).__name__}: {e}")

            # 1.5 ä¼°å€¼æŒ‡æ ‡å…œåº•ï¼šä»æŒ‡æ ‡æ¥å£è¡¥é½ PE/PB/å¸‚å€¼
            if (result.get("pe_ttm", 0) == 0 or result.get("pb", 0) == 0 or result.get("total_mv", 0) == 0):
                try:
                    extra = self._get_indicator_snapshot(symbol, max_retries=max(1, self._spot_retry))
                    if extra and extra.get("ok"):
                        updated = False
                        if result.get("pe_ttm", 0) == 0 and extra.get("pe_ttm") is not None and self._is_valid_num(extra.get("pe_ttm")):
                            result["pe_ttm"] = extra.get("pe_ttm", 0.0)
                            updated = True
                        if result.get("pb", 0) == 0 and extra.get("pb") is not None and self._is_valid_num(extra.get("pb")):
                            result["pb"] = extra.get("pb", 0.0)
                            updated = True
                        if result.get("total_mv", 0) == 0 and extra.get("total_mv") is not None and self._is_valid_num(extra.get("total_mv")):
                            result["total_mv"] = extra.get("total_mv", 0.0)
                            updated = True
                        if updated:
                            result["_ok"]["spot"] = True
                except Exception as e:
                    result["_err"].append(f"indicator_fallback_error: {type(e).__name__}: {e}")

            # 2. æ·±åº¦æŒ‡æ ‡ï¼šä¼˜å…ˆä½¿ç”¨ THS è´¢åŠ¡æ‘˜è¦ï¼ˆç»éªŒè¯å¯ç”¨ï¼›EMæ¥å£åœ¨ä½ ç¯å¢ƒé‡Œå…¨é‡æŠ¥é”™ï¼‰
            # å·¥ä¸šçº§ä¼˜åŒ–ï¼šæ·»åŠ é‡è¯•æœºåˆ¶
            ths_success = False
            for attempt in range(max(1, self._spot_retry + 1)):
                try:
                    with no_proxy_env():
                        ths_df = ak.stock_financial_abstract_ths(symbol=symbol)
                    if ths_df is not None and not ths_df.empty:
                        # å–æœ€æ–°æŠ¥å‘ŠæœŸ
                        if "æŠ¥å‘ŠæœŸ" in ths_df.columns:
                            tmp = ths_df.copy()
                            tmp["æŠ¥å‘ŠæœŸ_dt"] = pd.to_datetime(tmp["æŠ¥å‘ŠæœŸ"], errors="coerce")
                            tmp = tmp.sort_values("æŠ¥å‘ŠæœŸ_dt")
                            latest = tmp.iloc[-1]
                            result["report_date"] = str(latest.get("æŠ¥å‘ŠæœŸ", result["report_date"]))
                        else:
                            latest = ths_df.iloc[-1]

                        # å…³é”®æŒ‡æ ‡ï¼ˆå­—æ®µåç¨³å®šï¼‰
                        result["roe"] = self._to_f(latest.get("å‡€èµ„äº§æ”¶ç›Šç‡"))
                        result["net_profit_margin"] = self._to_f(latest.get("é”€å”®å‡€åˆ©ç‡"))
                        result["gross_margin"] = self._to_f(latest.get("é”€å”®æ¯›åˆ©ç‡"))
                        result["current_ratio"] = self._to_f(latest.get("æµåŠ¨æ¯”ç‡"))
                        result["debt_asset_ratio"] = self._to_f(latest.get("èµ„äº§è´Ÿå€ºç‡"))
                        # è¿™äº›å­—æ®µæœ‰æ—¶ä¸º False/ç©ºï¼Œ_to_f ä¼šå®‰å…¨å…œåº•ä¸º0.0
                        result["rev_growth"] = self._to_f(latest.get("è¥ä¸šæ€»æ”¶å…¥åŒæ¯”å¢é•¿ç‡"))
                        result["profit_growth"] = self._to_f(latest.get("å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡"))

                        if 0 < result["debt_asset_ratio"] < 100:
                            result["leverage"] = round(1 / (1 - result["debt_asset_ratio"] / 100), 2)

                        # å‡€åˆ©æ¶¦ï¼ˆç”¨äºä¼°ç®—PEï¼Œè‹¥ç¼ºå¤±ï¼‰
                        np_col = next((c for c in ths_df.columns if "å½’æ¯å‡€åˆ©æ¶¦" in str(c) or "å‡€åˆ©æ¶¦" in str(c)), None)
                        if np_col:
                            np_val = self._to_f(latest.get(np_col))
                            if self._is_valid_num(np_val):
                                result["net_profit"] = round(np_val / 100000000, 2) if np_val > 1e6 else round(np_val, 2)

                        # THS æ•°æ®ä¸­è‹¥åŒ…å«ä¼°å€¼å­—æ®µï¼Œé¡ºä¾¿è¡¥é½ PE/PB
                        if result.get("pe_ttm", 0) == 0:
                            pe_col = next((c for c in ths_df.columns if "å¸‚ç›ˆç‡" in str(c) or "PE" in str(c).upper()), None)
                            if pe_col:
                                pe_val = self._to_f(latest.get(pe_col))
                                if self._is_valid_num(pe_val):
                                    result["pe_ttm"] = pe_val
                                    result["_ok"]["spot"] = True
                        if result.get("pb", 0) == 0:
                            pb_col = next((c for c in ths_df.columns if "å¸‚å‡€ç‡" in str(c) or "PB" in str(c).upper()), None)
                            if pb_col:
                                pb_val = self._to_f(latest.get(pb_col))
                                if self._is_valid_num(pb_val):
                                    result["pb"] = pb_val
                                    result["_ok"]["spot"] = True

                        result["_ok"]["finance"] = True
                        ths_success = True
                        break  # æˆåŠŸè·å–ï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                    else:
                        if attempt < self._spot_retry:
                            time.sleep(0.5 * (attempt + 1))
                            continue
                        result["_err"].append("ths_finance_empty")
                except Exception as e:
                    if attempt < self._spot_retry:
                        time.sleep(0.5 * (attempt + 1))
                        continue
                    result["_err"].append(f"ths_finance_error (å°è¯•{attempt+1}/{self._spot_retry+1}): {type(e).__name__}: {e}")
            
            # é™çº§ç­–ç•¥ï¼šå¦‚æœTHSæ¥å£å¤±è´¥ï¼Œå°è¯•å…¶ä»–è´¢åŠ¡æ¥å£
            if not ths_success:
                # å°è¯•ä½¿ç”¨å…¶ä»–è´¢åŠ¡æ¥å£ä½œä¸ºé™çº§
                try:
                    # å¯ä»¥å°è¯•å…¶ä»–æ¥å£ï¼Œä½†è¿™é‡Œå…ˆä¿æŒåŸæœ‰é€»è¾‘
                    pass
                except Exception as e:
                    result["_err"].append(f"finance_fallback_error: {type(e).__name__}: {e}")

            # 3. è‹¥ä»æ‹¿ä¸åˆ° ROEï¼Œåˆ™ç”¨ PB/PE æ¨ç®—ï¼ˆæ ‡æ³¨ä¸ºæ¨ç®—ï¼Œä¸å†é»˜é»˜å†™0ï¼‰
            if not result["_ok"]["finance"] and result["pe_ttm"] > 0:
                result["roe"] = round((result["pb"] / result["pe_ttm"]) * 100, 2)
                # åªä½œä¸ºå…œåº•æ¨ç®—ï¼Œä¸å†™å…¥ _ok.finance
                result["_err"].append("roe_estimated_by_pb_pe")

            # 3.5 è‹¥ PE ä»ç¼ºå¤±ä½†å·²æœ‰ PB ä¸ ROEï¼Œåæ¨ PEï¼ˆå…œåº•ï¼‰
            if result.get("pe_ttm", 0) == 0 and result.get("pb", 0) > 0 and result.get("roe", 0) > 0:
                try:
                    result["pe_ttm"] = round(result["pb"] / (result["roe"] / 100.0), 2)
                    result["_ok"]["spot"] = True
                    result["_err"].append("pe_estimated_by_pb_roe")
                except Exception:
                    pass

            # 3.6 è‹¥ PE ä»ç¼ºå¤±ä½†å·²æœ‰å¸‚å€¼ä¸å‡€åˆ©æ¶¦ï¼Œåæ¨ PEï¼ˆå…œåº•ï¼‰
            if result.get("pe_ttm", 0) == 0 and result.get("total_mv", 0) > 0 and result.get("net_profit", 0) > 0:
                try:
                    result["pe_ttm"] = round(result["total_mv"] / (result["net_profit"] + 1e-8), 2)
                    result["_ok"]["spot"] = True
                    result["_err"].append("pe_estimated_by_mv_np")
                except Exception:
                    pass

            # 3.7 ç»Ÿä¸€æ€»å¸‚å€¼å•ä½ï¼ˆäº¿å…ƒï¼‰
            if self._is_valid_num(result.get("total_mv", 0), allow_zero=True):
                try:
                    mv_val = float(result.get("total_mv", 0))
                    if mv_val > 1e6:
                        result["total_mv"] = round(mv_val / 100000000, 2)
                except Exception:
                    pass

            # 4. æœ€ç»ˆå…œåº•ï¼šè‹¥ä¼°å€¼å­—æ®µå·²å–å¾—ï¼Œè¡¥æ ‡ spot OKï¼ˆåªæœ‰çœŸæ­£è·å–åˆ°æœ‰æ•ˆå€¼æ‰æ ‡è®°ï¼‰
            if not result["_ok"]["spot"]:
                if (
                    self._is_valid_num(result.get("pe_ttm", 0))
                    or self._is_valid_num(result.get("pb", 0))
                    or self._is_valid_num(result.get("total_mv", 0))
                ):
                    result["_ok"]["spot"] = True
                else:
                    # å¦‚æœæ‰€æœ‰ä¼°å€¼å­—æ®µéƒ½æ˜¯0ï¼Œæ˜ç¡®æ ‡è®°ä¸ºå¤±è´¥
                    if not result["_err"] or "spot_retry_failed" not in str(result["_err"]):
                        result["_err"].append("ä¼°å€¼æ•°æ®è·å–å¤±è´¥ï¼šPE/PB/å¸‚å€¼å‡ä¸º0æˆ–ä¸å¯ç”¨")

            # è¡¥é½è¡Œä¸šä¿¡æ¯ï¼ˆæ¥è‡ªç¼“å­˜/spotï¼‰
            if not result.get("industry") and symbol in self._industry_cache:
                result["industry"] = self._industry_cache.get(symbol)
            if result.get("industry"):
                self._industry_cache[symbol] = result.get("industry")
                if not force_live:
                    self._save_industry_cache()

        except Exception as e:
            result["_err"].append(f"spot_error: {type(e).__name__}: {e}")
            print(f"âš ï¸ è´¢æŠ¥å¼‚å¸¸: {e}")

        return result

    def _get_spot_df_cached(self, result: dict, force_refresh: bool = False):
        """
        è·å–å…¨å¸‚åœº spot æ•°æ®ï¼ˆå¸¦ç¼“å­˜ + é‡è¯•ï¼‰ã€‚
        å·¥ä¸šçº§ä¼˜åŒ–ï¼šå¢å¼ºé‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
        """
        now = time.time()
        if not force_refresh and self._spot_cache_df is not None and (now - self._spot_cache_ts) < self._spot_cache_ttl_sec:
            return self._spot_cache_df

        last_err = None
        max_retries = max(1, self._spot_retry + 1)
        for i in range(max_retries):
            try:
                with no_proxy_env():
                    df = ak.stock_zh_a_spot_em()
                if df is None or df.empty:
                    raise RuntimeError("spot_df_empty")
                # æ ‡å‡†åŒ–ä»£ç åˆ—ä¸º6ä½
                code_col = next((c for c in df.columns if 'ä»£ç ' in c), None)
                if code_col:
                    df[code_col] = df[code_col].astype(str).str.zfill(6)
                self._spot_cache_df = df
                self._spot_cache_ts = now
                self._save_spot_cache(df)
                return df
            except Exception as e:
                last_err = e
                # æŒ‡æ•°é€€é¿ï¼Œé™ä½ç¬æ—¶æ³¢åŠ¨/é™æµå½±å“
                if i < max_retries - 1:
                    time.sleep(0.5 * (i + 1))  # 0.5s, 1s, 1.5s...

        # ç½‘ç»œå¤±è´¥æ—¶ï¼Œå°è¯•è¯»å–è½ç›˜ç¼“å­˜
        if self._spot_cache_df is None and os.path.exists(self._spot_cache_path):
            try:
                df = pd.read_csv(self._spot_cache_path)
                if df is not None and not df.empty:
                    self._spot_cache_df = df
                    self._spot_cache_ts = now
                    return df
            except Exception:
                pass

        # è‹¥å¼ºåˆ¶åˆ·æ–°å¤±è´¥ä½†å·²æœ‰å†…å­˜ç¼“å­˜ï¼Œç›´æ¥å›é€€å†…å­˜ç¼“å­˜ï¼Œé¿å…PE/PB/è¡Œä¸šåŒæ—¶ç¼ºå¤±
        if self._spot_cache_df is not None and not self._spot_cache_df.empty:
            if last_err is not None:
                result["_err"].append(f"spot_refresh_failed_use_cache: {type(last_err).__name__}: {last_err}")
            self._spot_cache_ts = now
            return self._spot_cache_df

        if last_err is not None:
            result["_err"].append(f"spot_retry_failed (å°è¯•{max_retries}æ¬¡): {type(last_err).__name__}: {last_err}")
        return None

    def _get_spot_df_live(self, result: dict):
        """
        å¼ºåˆ¶å®æ—¶æ‹‰å–spotï¼Œä¸è¯»å†™ç¼“å­˜ã€‚
        """
        last_err = None
        max_retries = max(1, self._spot_retry + 1)
        for i in range(max_retries):
            try:
                with no_proxy_env():
                    df = ak.stock_zh_a_spot_em()
                if df is None or df.empty:
                    raise RuntimeError("spot_df_empty")
                code_col = next((c for c in df.columns if 'ä»£ç ' in c), None)
                if code_col:
                    df[code_col] = df[code_col].astype(str).str.zfill(6)
                return df
            except Exception as e:
                last_err = e
                if i < max_retries - 1:
                    time.sleep(0.5 * (i + 1))
        # è‹¥å®æ—¶å¤±è´¥ï¼Œå°è¯•è¯»å–è½ç›˜ç¼“å­˜ï¼Œé¿å…PE/è¡Œä¸šåŒæ—¶ç¼ºå¤±
        try:
            if os.path.exists(self._spot_cache_path):
                df = pd.read_csv(self._spot_cache_path)
                if df is not None and not df.empty:
                    code_col = next((c for c in df.columns if 'ä»£ç ' in c), None)
                    if code_col:
                        df[code_col] = df[code_col].astype(str).str.zfill(6)
                    if last_err is not None:
                        result["_err"].append(f"spot_live_failed_use_cache: {type(last_err).__name__}: {last_err}")
                    return df
        except Exception:
            pass
        if last_err is not None:
            result["_err"].append(f"spot_live_failed (å°è¯•{max_retries}æ¬¡): {type(last_err).__name__}: {last_err}")
        return None

    def _get_indicator_snapshot(self, symbol: str, max_retries: int = 2):
        """
        ä¼°å€¼æŒ‡æ ‡å…œåº•ï¼šå°è¯•ä» A è‚¡æŒ‡æ ‡æ¥å£æå– PE/PB/å¸‚å€¼
        """
        symbol = str(symbol).strip().zfill(6)

        def _symbol_variants(sym: str):
            s = str(sym).strip().zfill(6)
            variants = [s]
            exchange = "SH" if s.startswith(("6", "9")) else "SZ"
            variants.append(f"{s}.{exchange}")
            variants.append(f"{exchange}{s}")
            variants.append(f"{exchange.lower()}{s}")
            return list(dict.fromkeys(variants))

        def _pick_col(df, keywords):
            cols = list(df.columns)
            for c in cols:
                c_low = str(c).lower()
                for kw in keywords:
                    kw_low = kw.lower()
                    if kw_low in c_low or kw in str(c):
                        return c
            return None

        # æ‰©å±•æ¥å£åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•
        fetchers = []
        # ä¼˜å…ˆçº§1ï¼šæœ€å¸¸ç”¨çš„æ¥å£
        if hasattr(ak, "stock_a_indicator_lg"):
            fetchers.append(("stock_a_indicator_lg", lambda s: ak.stock_a_indicator_lg(symbol=s), True))
        if hasattr(ak, "stock_zh_a_indicator"):
            fetchers.append(("stock_zh_a_indicator", lambda s: ak.stock_zh_a_indicator(symbol=s), True))
        if hasattr(ak, "stock_a_indicator"):
            fetchers.append(("stock_a_indicator", lambda s: ak.stock_a_indicator(symbol=s), True))
        # ä¼˜å…ˆçº§2ï¼šå®æ—¶è¡Œæƒ…æ¥å£ï¼ˆä½œä¸ºæœ€åå…œåº•ï¼‰
        if hasattr(ak, "stock_zh_a_spot_em"):
            fetchers.append(("stock_zh_a_spot_em", lambda s: ak.stock_zh_a_spot_em().query(f"ä»£ç  == '{symbol}'"), False))

        symbol_variants = _symbol_variants(symbol)

        for name, fetch, use_variant in fetchers:
            symbols_to_try = symbol_variants if use_variant else [symbol]
            for sym in symbols_to_try:
                for attempt in range(max_retries):
                    try:
                        with no_proxy_env():
                            df = fetch(sym)
                    except Exception as e:
                        if attempt < max_retries - 1:
                            time.sleep(0.5 * (attempt + 1))
                            continue
                        continue
                    if df is None or df.empty:
                        continue
                    # å¦‚æœæ˜¯DataFrameï¼Œå–ç¬¬ä¸€è¡Œæˆ–æœ€åä¸€è¡Œ
                    if isinstance(df, pd.DataFrame):
                        if len(df) > 0:
                            latest = df.iloc[-1] if "trade_date" not in df.columns else df.sort_values("trade_date").iloc[-1]
                        else:
                            continue
                    else:
                        continue

                    pe_col = _pick_col(df, ["pe_ttm", "å¸‚ç›ˆç‡", "PE", "TTM", "å¸‚ç›ˆç‡TTM"])
                    pb_col = _pick_col(df, ["pb", "å¸‚å‡€ç‡", "PB"])
                    mv_col = _pick_col(df, ["total_mv", "æ€»å¸‚å€¼", "å¸‚å€¼", "æµé€šå¸‚å€¼", "market_cap"])

                    pe_ttm = self._to_f(latest.get(pe_col)) if pe_col and pe_col in latest.index else None
                    pb = self._to_f(latest.get(pb_col)) if pb_col and pb_col in latest.index else None
                    total_mv = self._to_f(latest.get(mv_col)) if mv_col and mv_col in latest.index else None
                    if self._is_valid_num(total_mv, allow_zero=True):
                        try:
                            if float(total_mv) > 1e6:
                                total_mv = float(total_mv) / 100000000
                        except Exception:
                            pass

                    # åªæœ‰çœŸæ­£è·å–åˆ°æœ‰æ•ˆå€¼æ‰è¿”å›
                    if self._is_valid_num(pe_ttm):
                        return {
                            "pe_ttm": pe_ttm,
                            "pb": pb if self._is_valid_num(pb) else None,
                            "total_mv": total_mv if self._is_valid_num(total_mv) else None,
                            "ok": True
                        }
                    if self._is_valid_num(pb):
                        return {
                            "pe_ttm": None,
                            "pb": pb,
                            "total_mv": total_mv if self._is_valid_num(total_mv) else None,
                            "ok": True
                        }
                    if self._is_valid_num(total_mv):
                        return {"pe_ttm": None, "pb": None, "total_mv": total_mv, "ok": True}
        return None

    def _get_industry_board_names(self, max_retries: int = 2):
        now = time.time()
        if self._industry_board_names and (now - self._industry_board_ts) < self._industry_board_ttl_sec:
            return self._industry_board_names
        sources = []
        if hasattr(ak, "stock_board_industry_name_em"):
            sources.append(ak.stock_board_industry_name_em)
        if hasattr(ak, "stock_board_industry_name_ths"):
            sources.append(ak.stock_board_industry_name_ths)
        if not sources:
            return []
        for fetch in sources:
            for attempt in range(max_retries):
                try:
                    with no_proxy_env():
                        df = fetch()
                    if df is None or df.empty:
                        continue
                    name_col = next((c for c in df.columns if "æ¿å—" in c or "è¡Œä¸š" in c or "åç§°" in c), None)
                    if not name_col:
                        name_col = df.columns[0]
                    names = [str(x).strip() for x in df[name_col].dropna().tolist() if str(x).strip()]
                    if names:
                        self._industry_board_names = names
                        self._industry_board_ts = now
                        return names
                except Exception:
                    if attempt < max_retries - 1:
                        time.sleep(0.3 * (attempt + 1))
                        continue
        return []

    def _normalize_industry_name(self, name: str):
        if not name:
            return ""
        n = str(name).strip()
        # å»æ‰æ‹¬å·å†…å®¹ï¼ˆå¦‚ â€œè®¡ç®—æœºè®¾å¤‡(ç”³ä¸‡)â€ï¼‰
        for sep in ["(", "ï¼ˆ"]:
            if sep in n:
                n = n.split(sep)[0].strip()
        # å»æ‰å¸¸è§åç¼€
        for suffix in ["è¡Œä¸š", "æ¿å—", "æ¦‚å¿µ", "æŒ‡æ•°", "ç±»"]:
            if n.endswith(suffix):
                n = n[: -len(suffix)].strip()
        # å»æ‰ç©ºç™½
        n = n.replace(" ", "")
        return n

    def _match_industry_board_name(self, industry: str):
        if not industry:
            return None
        industry = self._normalize_industry_name(industry)
        names = self._get_industry_board_names()
        if not names:
            return None
        # ä¼˜å…ˆå®Œå…¨åŒ¹é…
        for name in names:
            if industry == self._normalize_industry_name(name):
                return name
        # å…¶æ¬¡åŒ…å«åŒ¹é…
        for name in names:
            norm = self._normalize_industry_name(name)
            if industry in norm or norm in industry:
                return name
        return None

    def _lookup_industry_from_boards(self, symbol: str, max_retries: int = 2, max_scan: int = 200):
        symbol = str(symbol).strip().zfill(6)
        now = time.time()
        if symbol in self._industry_map and (now - self._industry_map_ts) < self._industry_map_ttl_sec:
            return self._industry_map[symbol]
        if not hasattr(ak, "stock_board_industry_cons_em"):
            return None

        names = self._get_industry_board_names()
        if not names:
            return None

        scanned = 0
        for name in names:
            scanned += 1
            if max_scan and scanned > max_scan:
                break
            codes = self._industry_cons_cache.get(name)
            if codes is None:
                cons_df = None
                for attempt in range(max_retries):
                    try:
                        with no_proxy_env():
                            cons_df = ak.stock_board_industry_cons_em(symbol=name)
                        if cons_df is not None and not cons_df.empty:
                            break
                    except Exception:
                        if attempt < max_retries - 1:
                            time.sleep(0.3 * (attempt + 1))
                            continue
                if cons_df is None or cons_df.empty:
                    continue
                code_col = next((c for c in cons_df.columns if "ä»£ç " in c or "è¯åˆ¸ä»£ç " in c or "stock_code" in c), None)
                if not code_col:
                    continue
                codes = set(cons_df[code_col].astype(str).str.zfill(6).tolist())
                self._industry_cons_cache[name] = codes
            if symbol in codes:
                self._industry_map[symbol] = name
                self._industry_map_ts = now
                return name
        return None

    # ... (get_industry_peers, _find_val, _to_f ä¿æŒä¸å˜ï¼Œç›´æ¥å¤ç”¨åŸæœ‰çš„å³å¯) ...
    # ä¸ºäº†å®Œæ•´æ€§ï¼Œè¿™é‡Œç®€å†™ä¿ç•™è¾…åŠ©å‡½æ•°ç»“æ„
    def get_industry_peers(self, symbol, max_retries=3, force_live: bool = False):
        """
        å·¥ä¸šçº§ä¼˜åŒ–ï¼šè·å–è¡Œä¸šå’ŒåŒè¡Œå¯¹æ¯”æ•°æ®
        æ·»åŠ é‡è¯•æœºåˆ¶å’Œé™çº§ç­–ç•¥
        """
        symbol = str(symbol).strip().zfill(6)
        if (not force_live) and symbol in self._peers_cache:
            cached_ind, cached_peers = self._peers_cache[symbol]
            if cached_peers is not None and len(cached_peers) >= 2 and cached_ind not in ["æœªçŸ¥", "ä¸Šæµ·ä¸»æ¿", "æ·±åœ³ä¸»æ¿", "åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿", None]:
                return self._peers_cache[symbol]

        industry = None if force_live else self._industry_cache.get(symbol)
        # 1) ä¸ªè‚¡ä¿¡æ¯æ¥å£ï¼ˆå¯èƒ½ä¸ç¨³å®šï¼‰- æ·»åŠ é‡è¯•æœºåˆ¶
        if not industry:
            for attempt in range(max_retries):
                try:
                    with no_proxy_env():
                        info_df = ak.stock_individual_info_em(symbol=symbol)
                    if info_df is not None and not info_df.empty and "item" in info_df.columns:
                        row = info_df[info_df["item"].astype(str).str.contains("è¡Œä¸š|æ‰€å±è¡Œä¸š")]
                        if not row.empty:
                            industry = str(row["value"].values[0]).strip()
                            break
                    if attempt < max_retries - 1:
                        time.sleep(0.5 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                except Exception as e:
                    if attempt < max_retries - 1:
                        time.sleep(0.5 * (attempt + 1))
                        continue
                    print(f"âš ï¸ è·å–ä¸ªè‚¡ä¿¡æ¯å¤±è´¥ ({symbol}): {e}")
                    industry = None

        # 2) ä½¿ç”¨ç¼“å­˜çš„å…¨å¸‚åœºspotå…œåº•
        dummy = {"_err": []}
        spot_df = self._get_spot_df_live(dummy) if force_live else self._get_spot_df_cached(dummy)
        if not industry and spot_df is not None and not spot_df.empty:
            code_col = next((c for c in spot_df.columns if 'ä»£ç ' in c), None)
            ind_col = next((c for c in spot_df.columns if 'è¡Œä¸š' in c), None)
            if code_col and ind_col:
                row = spot_df[spot_df[code_col].astype(str).str.zfill(6) == symbol]
                if not row.empty:
                    industry = str(row[ind_col].values[0]).strip()

        # 2.5) è¡Œä¸šå…œåº•ï¼šä»è¡Œä¸šæ¿å—æˆåˆ†åæŸ¥
        if not industry or industry == "æœªçŸ¥":
            industry = self._lookup_industry_from_boards(symbol, max_retries=max_retries)

        # 3) æœ€åå…œåº•ï¼šæ¿å—æŒ‰ä»£ç å‰ç¼€
        if not industry:
            prefix = symbol[:2]
            industry = {"60": "ä¸Šæµ·ä¸»æ¿", "00": "æ·±åœ³ä¸»æ¿", "30": "åˆ›ä¸šæ¿", "68": "ç§‘åˆ›æ¿"}.get(prefix, "æœªçŸ¥")

        # ä¿å­˜è¡Œä¸šç¼“å­˜ï¼ˆè½ç›˜ï¼‰
        if industry and industry not in ["æœªçŸ¥", "ä¸Šæµ·ä¸»æ¿", "æ·±åœ³ä¸»æ¿", "åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿"] and not force_live:
            self._industry_cache[symbol] = industry
            self._save_industry_cache()

        # 4) æ„å»ºåŒè¡Œå¯¹æ¯”
        # å·¥ä¸šçº§ä¼˜åŒ–ï¼šå¦‚æœspot_dfä¸ºç©ºï¼Œå°è¯•é‡æ–°è·å–ï¼ˆå¸¦é‡è¯•ï¼‰
        try:
            if spot_df is None or spot_df.empty:
                # å°è¯•é‡æ–°è·å–å…¨å¸‚åœºæ•°æ®ï¼ˆå¸¦é‡è¯•ï¼‰
                dummy = {"_err": []}
                full_market = self._get_spot_df_live(dummy) if force_live else self._get_spot_df_cached(dummy)
                if full_market is None or full_market.empty:
                    # æœ€åå°è¯•ç›´æ¥è°ƒç”¨ï¼ˆä¸å¸¦ç¼“å­˜ï¼‰
                    for attempt in range(max_retries):
                        try:
                            with no_proxy_env():
                                full_market = ak.stock_zh_a_spot_em()
                            if full_market is not None and not full_market.empty:
                                break
                            if attempt < max_retries - 1:
                                time.sleep(0.5 * (attempt + 1))
                        except Exception as e:
                            if attempt < max_retries - 1:
                                time.sleep(0.5 * (attempt + 1))
                                continue
                            print(f"âš ï¸ è·å–å…¨å¸‚åœºæ•°æ®å¤±è´¥ (å°è¯•{attempt+1}/{max_retries}): {e}")
                    if full_market is None or full_market.empty:
                        return industry or "æœªçŸ¥", pd.DataFrame()
            else:
                full_market = spot_df.copy()

            # æ›´å®½æ¾çš„åˆ—ååŒ¹é…
            code_col = next((c for c in full_market.columns if 'ä»£ç ' in c or 'code' in str(c).lower()), None)
            name_col = next((c for c in full_market.columns if 'åç§°' in c or 'name' in str(c).lower() or 'è‚¡ç¥¨ç®€ç§°' in c), None)
            ind_col = next((c for c in full_market.columns if 'è¡Œä¸š' in c or 'industry' in str(c).lower()), None)
            mkt_cap_col = next((c for c in full_market.columns if 'æ€»å¸‚å€¼' in c), None) or next((c for c in full_market.columns if 'å¸‚å€¼' in c and 'æµé€š' not in c), None) or next((c for c in full_market.columns if 'å¸‚å€¼' in c), None)
            pe_col = next((c for c in full_market.columns if 'å¸‚ç›ˆç‡' in c and ('åŠ¨' in c or 'TTM' in c)), None) or next((c for c in full_market.columns if 'å¸‚ç›ˆç‡' in c), None) or next((c for c in full_market.columns if 'PE' in str(c).upper()), None)
            pb_col = next((c for c in full_market.columns if 'å¸‚å‡€ç‡' in c), None) or next((c for c in full_market.columns if 'PB' in str(c).upper()), None)

            if code_col:
                full_market[code_col] = full_market[code_col].astype(str).str.zfill(6)

            peers_df = pd.DataFrame()
            cons_df_cached = None
            
            # ä¼˜å…ˆå°è¯•ï¼šé€šè¿‡è¡Œä¸šåç§°è·å–è¯¥è¡Œä¸šæˆåˆ†è‚¡ (ä¿®å¤ï¼šç´«é‡‘çŸ¿ä¸šåŒ¹é…é“¶è¡Œé—®é¢˜)
            # å·¥ä¸šçº§ä¼˜åŒ–ï¼šæ·»åŠ é‡è¯•æœºåˆ¶
            if industry and industry not in ["æœªçŸ¥", "ä¸Šæµ·ä¸»æ¿", "æ·±åœ³ä¸»æ¿", "åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿"]:
                for attempt in range(max_retries):
                    try:
                        # è·å–è¡Œä¸šæˆåˆ†è‚¡ä»£ç åˆ—è¡¨ï¼ˆå¤šåç§°å°è¯•ï¼‰
                        board_name = self._match_industry_board_name(industry) or industry
                        norm = self._normalize_industry_name(board_name)
                        board_candidates = []
                        for n in [board_name, norm, f"{norm}è¡Œä¸š", f"{norm}æ¿å—"]:
                            if n and n not in board_candidates:
                                board_candidates.append(n)
                        # æ¨¡ç³ŠåŒ¹é…è¡Œä¸šåç§°ï¼ˆåº”å¯¹â€œè®¡ç®—æœºè®¾å¤‡(ç”³ä¸‡)â€ç­‰å·®å¼‚ï¼‰
                        try:
                            names = self._get_industry_board_names()
                            if names:
                                for name in names:
                                    if norm and norm in self._normalize_industry_name(name):
                                        if name not in board_candidates:
                                            board_candidates.append(name)
                                close = difflib.get_close_matches(industry, names, n=5, cutoff=0.6)
                                for name in close:
                                    if name not in board_candidates:
                                        board_candidates.append(name)
                        except Exception:
                            pass

                        cons_df = None
                        for bn in board_candidates:
                            if hasattr(ak, "stock_board_industry_cons_em"):
                                with no_proxy_env():
                                    cons_df = ak.stock_board_industry_cons_em(symbol=bn)
                            if (cons_df is None or cons_df.empty) and hasattr(ak, "stock_board_industry_cons_ths"):
                                with no_proxy_env():
                                    cons_df = ak.stock_board_industry_cons_ths(symbol=bn)
                            if (cons_df is None or cons_df.empty) and hasattr(ak, "stock_board_industry_cons_sina"):
                                with no_proxy_env():
                                    cons_df = ak.stock_board_industry_cons_sina(symbol=bn)
                            if cons_df is not None and not cons_df.empty:
                                break

                        # å¦‚æœä»å¤±è´¥ï¼Œå°è¯•ç”¨æˆåˆ†åæŸ¥ï¼ˆæ‰©å¤§æ‰«æèŒƒå›´ï¼‰
                        if (cons_df is None or cons_df.empty):
                            inferred = self._lookup_industry_from_boards(symbol, max_retries=max_retries, max_scan=800)
                            if inferred:
                                for bn in [inferred, self._normalize_industry_name(inferred), f"{self._normalize_industry_name(inferred)}è¡Œä¸š"]:
                                    if hasattr(ak, "stock_board_industry_cons_em"):
                                        with no_proxy_env():
                                            cons_df = ak.stock_board_industry_cons_em(symbol=bn)
                                    if cons_df is not None and not cons_df.empty:
                                        break

                        if cons_df is not None and not cons_df.empty:
                            cons_df_cached = cons_df.copy()
                            cons_code_col = next((c for c in cons_df.columns if 'ä»£ç ' in c or 'è¯åˆ¸ä»£ç ' in c or 'stock_code' in c), None)
                            if cons_code_col:
                                cons_codes = cons_df[cons_code_col].astype(str).str.zfill(6).tolist()
                                if cons_codes and code_col:
                                    peers_df = full_market[full_market[code_col].isin(cons_codes)].copy()
                                    if not peers_df.empty:
                                        break  # æˆåŠŸè·å–ï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                        if attempt < max_retries - 1:
                            time.sleep(0.5 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                    except Exception as e:
                        if attempt < max_retries - 1:
                            time.sleep(0.5 * (attempt + 1))
                            continue
                        print(f"âš ï¸ è·å–è¡Œä¸šæˆåˆ†è‚¡å¤±è´¥ ({industry}, å°è¯•{attempt+1}/{max_retries}): {e}")

            # å…œåº•1ï¼šå¦‚æœ spot_df è‡ªå¸¦è¡Œä¸šåˆ—ï¼Œä¸”ä¸Šé¢è·å–æˆåˆ†è‚¡å¤±è´¥
            if peers_df.empty and ind_col and industry not in ["æœªçŸ¥", "ä¸Šæµ·ä¸»æ¿", "æ·±åœ³ä¸»æ¿", "åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿"]:
                norm_ind = self._normalize_industry_name(industry)
                peers_df = full_market[full_market[ind_col].astype(str).apply(self._normalize_industry_name) == norm_ind].copy()

            # è‹¥åŒè¡Œè¿‡å°‘ï¼Œå°è¯•æ‰©å¤§åˆ°è¡Œä¸šåç§°åŒ¹é…
            if not peers_df.empty and len(peers_df) < 3 and ind_col and industry:
                broaden = full_market[full_market[ind_col].astype(str).str.contains(self._normalize_industry_name(industry), na=False)].copy()
                if len(broaden) > len(peers_df):
                    peers_df = broaden
            
            # ç§»é™¤ç²—æš´çš„æ¿å—å‰ç¼€å…œåº•ï¼Œé¿å…å°†ç´«é‡‘çŸ¿ä¸šï¼ˆæœ‰è‰²ï¼‰åŒ¹é…ä¸ºå¸‚å€¼æœ€é«˜çš„é“¶è¡Œè‚¡
            # if peers_df.empty:
            #    peers_df = full_market[full_market[code_col].astype(str).str.startswith(symbol[:2])].copy()

            if peers_df.empty:
                # å¦‚æœæ‰¾ä¸åˆ°åŒè¡Œï¼Œå°è¯•ç”¨å…¨éƒ¨Aè‚¡çš„åŒåè¡Œä¸šï¼ˆå¦‚æœspoté‡Œæœ‰è¡Œä¸šåˆ—ä½†æ²¡åŒ¹é…ä¸Šï¼‰
                if ind_col and industry:
                     peers_df = full_market[full_market[ind_col].astype(str).str.contains(self._normalize_industry_name(industry), na=False)].copy()
                
                # æˆåˆ†è‚¡å…œåº•ï¼šå¦‚æœ full_market åŒ¹é…å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨è¡Œä¸šæˆåˆ†è‚¡åˆ—è¡¨
                if (peers_df.empty or len(peers_df) < 2) and cons_df_cached is not None and not cons_df_cached.empty:
                    # å¦‚æœæˆåˆ†è‚¡è¡¨æœ‰ä»£ç åˆ—ï¼Œå°è¯•ä» full_market ä¸­åŒ¹é…è·å–å®Œæ•´æ•°æ®
                    cons_code_col = next((c for c in cons_df_cached.columns if 'ä»£ç ' in c or 'è¯åˆ¸ä»£ç ' in c or 'stock_code' in c), None)
                    if cons_code_col and code_col:
                        cons_codes = cons_df_cached[cons_code_col].astype(str).str.zfill(6).tolist()
                        if cons_codes:
                            matched = full_market[full_market[code_col].isin(cons_codes)].copy()
                            if not matched.empty:
                                peers_df = matched
                    # å¦‚æœè¿˜æ˜¯ç©ºï¼Œç›´æ¥ä½¿ç”¨æˆåˆ†è‚¡è¡¨ï¼ˆä½†éœ€è¦é‡æ–°è¯†åˆ«åˆ—åï¼‰
                    if peers_df.empty:
                        peers_df = cons_df_cached.copy()
                        # é‡æ–°è¯†åˆ«åˆ—åï¼ˆé’ˆå¯¹æˆåˆ†è‚¡è¡¨ï¼‰
                        code_col = next((c for c in peers_df.columns if 'ä»£ç ' in c or 'è¯åˆ¸ä»£ç ' in c or 'stock_code' in c), None)
                        name_col = next((c for c in peers_df.columns if 'åç§°' in c or 'è‚¡ç¥¨ç®€ç§°' in c or 'name' in str(c).lower()), None)
                        pe_col = next((c for c in peers_df.columns if 'å¸‚ç›ˆç‡' in c or 'PE' in str(c).upper()), None)
                        pb_col = next((c for c in peers_df.columns if 'å¸‚å‡€ç‡' in c or 'PB' in str(c).upper()), None)
                        mkt_cap_col = next((c for c in peers_df.columns if 'æ€»å¸‚å€¼' in c), None) or next((c for c in peers_df.columns if 'å¸‚å€¼' in c and 'æµé€š' not in c), None)

                # æœ€åå…œåº•ï¼šå¦‚æœè¡Œä¸šåŒ¹é…å¤±è´¥ï¼Œè‡³å°‘è¿”å›å¸‚å€¼ç›¸è¿‘çš„è‚¡ç¥¨ï¼ˆæ’é™¤å½“å‰è‚¡ç¥¨ï¼‰
                if peers_df.empty and code_col:
                    # å°è¯•æŒ‰å¸‚å€¼æ’åºï¼Œå–å‰10ä¸ªï¼ˆæ’é™¤å½“å‰è‚¡ç¥¨ï¼‰
                    if mkt_cap_col and mkt_cap_col in full_market.columns:
                        candidates = full_market[full_market[code_col] != symbol].copy()
                        if not candidates.empty:
                            candidates = candidates.sort_values(by=mkt_cap_col, ascending=False).head(10)
                            peers_df = candidates
                            print(f"âš ï¸ [{symbol}] è¡Œä¸šåŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨å¸‚å€¼å‰10ä½œä¸ºå¯¹æ ‡ï¼ˆè¡Œä¸š: {industry}ï¼‰")
                
                if peers_df.empty:
                    print(f"âš ï¸ [{symbol}] æ— æ³•è·å–è¡Œä¸šå¯¹æ ‡æ•°æ®ï¼ˆè¡Œä¸š: {industry}ï¼‰")
                    return industry, pd.DataFrame()
                
                # ç¡®ä¿æ’é™¤å½“å‰è‚¡ç¥¨ï¼Œä¸”è‡³å°‘æœ‰2ä¸ªåŒè¡Œ
                if code_col and code_col in peers_df.columns and len(peers_df) > 0:
                    peers_df = peers_df[peers_df[code_col] != symbol].copy()
                    if len(peers_df) < 2 and mkt_cap_col and mkt_cap_col in full_market.columns:
                        # å¦‚æœåŒè¡Œå¤ªå°‘ï¼Œè¡¥å……å¸‚å€¼ç›¸è¿‘çš„è‚¡ç¥¨
                        candidates = full_market[full_market[code_col] != symbol].copy()
                        if not candidates.empty:
                            candidates = candidates.sort_values(by=mkt_cap_col, ascending=False).head(6)
                            existing_codes = set(peers_df[code_col].tolist()) if code_col in peers_df.columns else set()
                            candidates = candidates[~candidates[code_col].isin(existing_codes)]
                            if len(candidates) > 0:
                                peers_df = pd.concat([peers_df, candidates.head(6 - len(peers_df))], ignore_index=True)

            # æ’é™¤å½“å‰è‚¡ç¥¨
            if code_col and code_col in peers_df.columns:
                peers_df = peers_df[peers_df[code_col] != symbol].copy()
            
            if peers_df.empty:
                print(f"âš ï¸ [{symbol}] æ’é™¤å½“å‰è‚¡ç¥¨åï¼Œæ— åŒè¡Œæ•°æ®")
                return industry, pd.DataFrame()
            
            if mkt_cap_col and mkt_cap_col in peers_df.columns:
                peers_df = peers_df.sort_values(by=mkt_cap_col, ascending=False).head(6).copy()
            else:
                peers_df = peers_df.head(6).copy()

            # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
            comparison_data = {}
            if code_col and code_col in peers_df.columns:
                comparison_data["ä»£ç "] = peers_df[code_col].astype(str).str.zfill(6).tolist()
            elif code_col:
                comparison_data["ä»£ç "] = peers_df.index.astype(str).tolist() if hasattr(peers_df.index, 'tolist') else [str(i) for i in peers_df.index]
            else:
                comparison_data["ä»£ç "] = [symbol] * len(peers_df)
            
            if name_col and name_col in peers_df.columns:
                comparison_data["åç§°"] = peers_df[name_col].astype(str).tolist()
            else:
                comparison_data["åç§°"] = [""] * len(peers_df)
            
            if pe_col and pe_col in peers_df.columns:
                comparison_data["PE(åŠ¨)"] = peers_df[pe_col].apply(self._to_f).tolist()
            else:
                comparison_data["PE(åŠ¨)"] = [0.0] * len(peers_df)
            
            if pb_col and pb_col in peers_df.columns:
                comparison_data["PB"] = peers_df[pb_col].apply(self._to_f).tolist()
            else:
                comparison_data["PB"] = [0.0] * len(peers_df)
            
            if mkt_cap_col and mkt_cap_col in peers_df.columns:
                comparison_data["å¸‚å€¼(äº¿)"] = (peers_df[mkt_cap_col].apply(self._to_f) / 100000000).round(2).tolist()
            else:
                comparison_data["å¸‚å€¼(äº¿)"] = [0.0] * len(peers_df)
            
            comparison_df = pd.DataFrame(comparison_data)
            comparison_df['ROE(æ¨ç®—%)'] = np.where(comparison_df['PE(åŠ¨)'] > 0,
                                                   (comparison_df['PB'] / comparison_df['PE(åŠ¨)'] * 100).round(2), 0.0)

            if not force_live:
                self._industry_cache[symbol] = industry
                self._peers_cache[symbol] = (industry, comparison_df)
            return industry, comparison_df
        except Exception:
            return industry or "æœªçŸ¥", pd.DataFrame()

    def _find_val(self, row, cols, keywords):
        for c in cols:
            if all(k in str(c) for k in keywords): return self._to_f(row[c])
        return 0.0

    def _is_valid_num(self, val, allow_zero: bool = False) -> bool:
        try:
            if val is None:
                return False
            f = float(val)
            if not np.isfinite(f):
                return False
            return True if allow_zero else f != 0
        except Exception:
            return False

    def _to_f(self, val):
        try:
            if val is None:
                return 0.0
            s = str(val).strip()
            if not s:
                return 0.0
            if s in ['-', '--', 'â€”', 'nan', 'NaN', 'N/A', 'NA', 'n/a', 'None', 'null', 'NULL']:
                return 0.0
            s = s.replace('å…ƒ', '')
            mult = 1.0
            if s.endswith("ä¸‡äº¿"):
                mult = 1e12
                s = s[:-2]
            elif s.endswith("äº¿"):
                mult = 1e8
                s = s[:-1]
            elif s.endswith("ä¸‡"):
                mult = 1e4
                s = s[:-1]
            s = s.replace('%', '').replace(',', '').replace('å€', '')
            return float(s) * mult
        except:
            return 0.0