"""
Top10 å½¢æ€åˆ†æå¢å¼ºæ¨¡å—
Enhanced Top-10 Pattern Analysis

å¢å¼ºTop10å¯¹æ¯”çš„ä¿¡æ¯é‡:
1. ç»Ÿè®¡ä¿¡æ¯ - å¹³å‡æ”¶ç›Šã€èƒœç‡åˆ†å¸ƒã€é£é™©æŒ‡æ ‡
2. æ—¶é—´åˆ†å¸ƒ - å¹´ä»½ã€æœˆä»½ã€å¸‚åœºå‘¨æœŸ
3. è¡Œä¸šåˆ†å¸ƒ - åŒ¹é…å½¢æ€æ¥è‡ªå“ªäº›è¡Œä¸š
4. æ”¶ç›Šè½¨è¿¹ - æ›´è¯¦ç»†çš„æœªæ¥èµ°åŠ¿å¯¹æ¯”

Author: VisionQuant Team
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
from collections import Counter
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec


class Top10Analyzer:
    """
    Top10å½¢æ€æ·±åº¦åˆ†æå™¨
    
    ç”¨æ³•:
    ```python
    analyzer = Top10Analyzer(data_loader)
    stats = analyzer.analyze_matches(matches)
    chart = analyzer.create_enhanced_chart(matches, query_img_path)
    ```
    """
    
    def __init__(self, data_loader=None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_loader: æ•°æ®åŠ è½½å™¨ï¼Œç”¨äºè·å–å†å²æ•°æ®
        """
        self.data_loader = data_loader
        
        # è¡Œä¸šæ˜ å°„ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self.industry_map = {
            '60': 'ä¸Šæµ·ä¸»æ¿',
            '00': 'æ·±åœ³ä¸»æ¿',
            '30': 'åˆ›ä¸šæ¿',
            '68': 'ç§‘åˆ›æ¿',
        }
        
    def analyze_matches(
        self,
        matches: List[Dict],
        future_days: int = 20
    ) -> Dict:
        """
        åˆ†æTop10åŒ¹é…ç»“æœ
        
        Args:
            matches: åŒ¹é…ç»“æœåˆ—è¡¨
            future_days: è®¡ç®—æœªæ¥æ”¶ç›Šçš„å¤©æ•°
            
        Returns:
            ç»Ÿè®¡åˆ†æç»“æœ
        """
        if not matches:
            return {'valid': False, 'message': 'æ— åŒ¹é…æ•°æ®'}
        
        # æ”¶é›†ç»Ÿè®¡æ•°æ®
        returns = []
        max_returns = []
        max_drawdowns = []
        hit_days = []  # è¾¾åˆ°æ­¢ç›ˆ/æ­¢æŸçš„å¤©æ•°
        years = []
        months = []
        boards = []  # æ¿å—
        
        for match in matches:
            symbol = str(match.get('symbol', '')).zfill(6)
            date_str = str(match.get('date', ''))
            
            # è§£ææ—¥æœŸ
            try:
                if '-' in date_str:
                    match_date = datetime.strptime(date_str, '%Y-%m-%d')
                else:
                    match_date = datetime.strptime(date_str, '%Y%m%d')
            except:
                continue
            
            years.append(match_date.year)
            months.append(match_date.month)
            
            # æ¿å—åˆ†ç±»
            prefix = symbol[:2]
            boards.append(self.industry_map.get(prefix, 'å…¶ä»–'))
            
            # è·å–æœªæ¥æ”¶ç›Šæ•°æ®
            if self.data_loader:
                try:
                    df = self.data_loader.get_stock_data(symbol)
                    if df is not None and not df.empty:
                        df.index = pd.to_datetime(df.index)
                        
                        if match_date in df.index:
                            loc = df.index.get_loc(match_date)
                            
                            if loc + future_days < len(df):
                                entry_price = df.iloc[loc]['Close']
                                future_prices = df.iloc[loc+1:loc+1+future_days]['Close']
                                
                                # è®¡ç®—æ”¶ç›Š
                                future_returns = (future_prices - entry_price) / entry_price * 100
                                
                                returns.append(future_returns.iloc[-1])
                                max_returns.append(future_returns.max())
                                max_drawdowns.append(future_returns.min())
                                
                                # è®¡ç®—é¦–æ¬¡è¾¾åˆ°5%çš„å¤©æ•°
                                above_5 = future_returns >= 5
                                if above_5.any():
                                    hit_days.append(above_5.idxmax())
                except:
                    pass
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        result = {
            'valid': True,
            'matches_count': len(matches),
            
            # æ”¶ç›Šç»Ÿè®¡
            'avg_return': np.mean(returns) if returns else 0,
            'median_return': np.median(returns) if returns else 0,
            'std_return': np.std(returns) if returns else 0,
            'min_return': np.min(returns) if returns else 0,
            'max_return': np.max(returns) if returns else 0,
            
            # èƒœç‡ç»Ÿè®¡
            'positive_count': sum(1 for r in returns if r > 0),
            'negative_count': sum(1 for r in returns if r < 0),
            'neutral_count': sum(1 for r in returns if r == 0),
            'win_rate': sum(1 for r in returns if r > 0) / len(returns) * 100 if returns else 0,
            
            # é£é™©ç»Ÿè®¡
            'avg_max_return': np.mean(max_returns) if max_returns else 0,
            'avg_max_drawdown': np.mean(max_drawdowns) if max_drawdowns else 0,
            
            # æ—¶é—´åˆ†å¸ƒ
            'year_distribution': dict(Counter(years)),
            'month_distribution': dict(Counter(months)),
            
            # æ¿å—åˆ†å¸ƒ
            'board_distribution': dict(Counter(boards)),
            
            # ç›¸ä¼¼åº¦ç»Ÿè®¡
            'avg_similarity': np.mean([m.get('score', 0) for m in matches]),
            'max_similarity': max([m.get('score', 0) for m in matches]),
            'min_similarity': min([m.get('score', 0) for m in matches]),
        }
        
        # è®¡ç®—é£é™©è°ƒæ•´æ”¶ç›Š
        if result['std_return'] > 0:
            result['sharpe_like'] = result['avg_return'] / result['std_return']
        else:
            result['sharpe_like'] = 0
        
        return result
    
    def get_return_trajectories(
        self,
        matches: List[Dict],
        future_days: int = 20
    ) -> pd.DataFrame:
        """
        è·å–æ‰€æœ‰åŒ¹é…å½¢æ€çš„æœªæ¥æ”¶ç›Šè½¨è¿¹
        
        Args:
            matches: åŒ¹é…ç»“æœ
            future_days: æœªæ¥å¤©æ•°
            
        Returns:
            DataFrameï¼Œæ¯åˆ—æ˜¯ä¸€ä¸ªåŒ¹é…å½¢æ€çš„æ”¶ç›Šè½¨è¿¹
        """
        if not self.data_loader:
            return pd.DataFrame()
        
        trajectories = {}
        
        for i, match in enumerate(matches):
            symbol = str(match.get('symbol', '')).zfill(6)
            date_str = str(match.get('date', ''))
            
            try:
                if '-' in date_str:
                    match_date = datetime.strptime(date_str, '%Y-%m-%d')
                else:
                    match_date = datetime.strptime(date_str, '%Y%m%d')
                    
                df = self.data_loader.get_stock_data(symbol)
                if df is not None and not df.empty:
                    df.index = pd.to_datetime(df.index)
                    
                    if match_date in df.index:
                        loc = df.index.get_loc(match_date)
                        
                        if loc + future_days < len(df):
                            entry_price = df.iloc[loc]['Close']
                            future_prices = df.iloc[loc:loc+1+future_days]['Close']
                            
                            returns = (future_prices - entry_price) / entry_price * 100
                            returns = returns.reset_index(drop=True)
                            
                            trajectories[f'Top{i+1}_{symbol}'] = returns
            except:
                continue
        
        return pd.DataFrame(trajectories)
    
    def create_stats_summary(self, stats: Dict) -> str:
        """
        ç”Ÿæˆç»Ÿè®¡æ‘˜è¦æ–‡æœ¬
        
        Args:
            stats: analyze_matchesè¿”å›çš„ç»Ÿè®¡ç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„æ‘˜è¦æ–‡æœ¬
        """
        if not stats.get('valid'):
            return "âš ï¸ æ— æœ‰æ•ˆç»Ÿè®¡æ•°æ®"
        
        summary = []
        summary.append("ğŸ“Š **Top10 å½¢æ€ç»Ÿè®¡åˆ†æ**")
        summary.append("")
        
        # æ”¶ç›Šç»Ÿè®¡
        summary.append("ğŸ’° **æ”¶ç›Šç»Ÿè®¡**")
        summary.append(f"- å¹³å‡æ”¶ç›Š: {stats['avg_return']:.2f}%")
        summary.append(f"- ä¸­ä½æ•°æ”¶ç›Š: {stats['median_return']:.2f}%")
        summary.append(f"- æ”¶ç›ŠåŒºé—´: [{stats['min_return']:.2f}%, {stats['max_return']:.2f}%]")
        summary.append(f"- æ³¢åŠ¨ç‡: {stats['std_return']:.2f}%")
        summary.append("")
        
        # èƒœç‡
        summary.append("ğŸ¯ **èƒœç‡åˆ†æ**")
        summary.append(f"- ä¸Šæ¶¨æ•°é‡: {stats['positive_count']}")
        summary.append(f"- ä¸‹è·Œæ•°é‡: {stats['negative_count']}")
        summary.append(f"- å†å²èƒœç‡: {stats['win_rate']:.1f}%")
        summary.append("")
        
        # é£é™©
        summary.append("âš ï¸ **é£é™©æŒ‡æ ‡**")
        summary.append(f"- å¹³å‡æœ€å¤§æ¶¨å¹…: {stats['avg_max_return']:.2f}%")
        summary.append(f"- å¹³å‡æœ€å¤§å›æ’¤: {stats['avg_max_drawdown']:.2f}%")
        summary.append(f"- é£é™©è°ƒæ•´æ”¶ç›Š: {stats['sharpe_like']:.2f}")
        summary.append("")
        
        # åˆ†å¸ƒ
        if stats.get('board_distribution'):
            summary.append("ğŸ“ **æ¿å—åˆ†å¸ƒ**")
            for board, count in stats['board_distribution'].items():
                summary.append(f"- {board}: {count}ä¸ª")
        
        return "\n".join(summary)


def create_enhanced_top10_chart(
    query_image_path: str,
    matches: List[Dict],
    stats: Dict,
    trajectories: pd.DataFrame,
    output_path: str
):
    """
    åˆ›å»ºå¢å¼ºç‰ˆTop10å¯¹æ¯”å›¾
    
    åŒ…å«:
    - æŸ¥è¯¢å›¾åƒå’ŒTop10åŒ¹é…å›¾
    - æ”¶ç›Šè½¨è¿¹å¯¹æ¯”å›¾
    - ç»Ÿè®¡ä¿¡æ¯é¢æ¿
    
    Args:
        query_image_path: æŸ¥è¯¢å›¾åƒè·¯å¾„
        matches: åŒ¹é…ç»“æœ
        stats: ç»Ÿè®¡ç»“æœ
        trajectories: æ”¶ç›Šè½¨è¿¹
        output_path: è¾“å‡ºè·¯å¾„
    """
    import os
    from PIL import Image
    
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
    
    fig = plt.figure(figsize=(24, 14))
    gs = gridspec.GridSpec(3, 8, figure=fig, height_ratios=[1.2, 1, 0.8])
    
    PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    IMG_BASE_DIR = os.path.join(PROJECT_ROOT, "data", "images")
    
    # === ç¬¬ä¸€è¡Œ: æŸ¥è¯¢å›¾ + Top5åŒ¹é… ===
    # æŸ¥è¯¢å›¾ï¼ˆå¤§ï¼‰
    ax_query = fig.add_subplot(gs[0, :2])
    if os.path.exists(query_image_path):
        img = Image.open(query_image_path)
        ax_query.imshow(img)
        ax_query.set_title("ğŸ“ å½“å‰å½¢æ€ (Query)", fontsize=14, fontweight='bold', color='blue')
    ax_query.axis('off')
    
    # Top1-5
    for i in range(min(5, len(matches))):
        ax = fig.add_subplot(gs[0, 2+i])
        match = matches[i]
        
        img_name = f"{match['symbol']}_{match['date']}.png"
        img_path = os.path.join(IMG_BASE_DIR, img_name)
        
        if os.path.exists(img_path):
            img = Image.open(img_path)
            ax.imshow(img)
            
        title = f"Top {i+1}\n{match['symbol']}\n{match['date']}\nSim: {match['score']:.3f}"
        ax.set_title(title, fontsize=10)
        ax.axis('off')
    
    # ç»Ÿè®¡é¢æ¿
    ax_stats = fig.add_subplot(gs[0, 7])
    ax_stats.axis('off')
    stats_text = f"""ğŸ“Š ç»Ÿè®¡æ‘˜è¦
    
èƒœç‡: {stats.get('win_rate', 0):.1f}%
å¹³å‡æ”¶ç›Š: {stats.get('avg_return', 0):.2f}%
æœ€å¤§æ”¶ç›Š: {stats.get('max_return', 0):.2f}%
æœ€å¤§å›æ’¤: {stats.get('avg_max_drawdown', 0):.2f}%
ç›¸ä¼¼åº¦: {stats.get('avg_similarity', 0):.3f}"""
    ax_stats.text(0.1, 0.9, stats_text, transform=ax_stats.transAxes,
                  fontsize=11, verticalalignment='top',
                  bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    # === ç¬¬äºŒè¡Œ: Top6-10 + æ”¶ç›Šè½¨è¿¹å›¾ ===
    for i in range(5, min(10, len(matches))):
        ax = fig.add_subplot(gs[1, i-5])
        match = matches[i]
        
        img_name = f"{match['symbol']}_{match['date']}.png"
        img_path = os.path.join(IMG_BASE_DIR, img_name)
        
        if os.path.exists(img_path):
            img = Image.open(img_path)
            ax.imshow(img)
            
        title = f"Top {i+1}\n{match['symbol']}\nSim: {match['score']:.3f}"
        ax.set_title(title, fontsize=9)
        ax.axis('off')
    
    # æ”¶ç›Šè½¨è¿¹å›¾
    ax_traj = fig.add_subplot(gs[1, 5:])
    if not trajectories.empty:
        for col in trajectories.columns:
            ax_traj.plot(trajectories[col], alpha=0.5, linewidth=1)
        
        # å¹³å‡è½¨è¿¹
        mean_traj = trajectories.mean(axis=1)
        ax_traj.plot(mean_traj, color='red', linewidth=3, label='å¹³å‡è½¨è¿¹')
        
        ax_traj.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        ax_traj.axhline(y=5, color='green', linestyle='--', alpha=0.3, label='æ­¢ç›ˆçº¿(+5%)')
        ax_traj.axhline(y=-3, color='red', linestyle='--', alpha=0.3, label='æ­¢æŸçº¿(-3%)')
        
        ax_traj.set_xlabel('æŒæœ‰å¤©æ•°')
        ax_traj.set_ylabel('æ”¶ç›Šç‡ (%)')
        ax_traj.set_title('ğŸ“ˆ æœªæ¥20å¤©æ”¶ç›Šè½¨è¿¹å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax_traj.legend(loc='upper right')
        ax_traj.grid(True, alpha=0.3)
    else:
        ax_traj.text(0.5, 0.5, 'æš‚æ— æ”¶ç›Šæ•°æ®', ha='center', va='center')
        ax_traj.axis('off')
    
    # === ç¬¬ä¸‰è¡Œ: åˆ†å¸ƒå›¾ ===
    # å¹´ä»½åˆ†å¸ƒ
    ax_year = fig.add_subplot(gs[2, :3])
    if stats.get('year_distribution'):
        years = list(stats['year_distribution'].keys())
        counts = list(stats['year_distribution'].values())
        ax_year.bar(years, counts, color='steelblue')
        ax_year.set_xlabel('å¹´ä»½')
        ax_year.set_ylabel('æ•°é‡')
        ax_year.set_title('ğŸ“… å¹´ä»½åˆ†å¸ƒ', fontsize=11)
    
    # æ¿å—åˆ†å¸ƒ
    ax_board = fig.add_subplot(gs[2, 3:6])
    if stats.get('board_distribution'):
        boards = list(stats['board_distribution'].keys())
        counts = list(stats['board_distribution'].values())
        colors = plt.cm.Pastel1(np.linspace(0, 1, len(boards)))
        ax_board.pie(counts, labels=boards, autopct='%1.0f%%', colors=colors)
        ax_board.set_title('ğŸ“Š æ¿å—åˆ†å¸ƒ', fontsize=11)
    
    # æ”¶ç›Šåˆ†å¸ƒ
    ax_ret = fig.add_subplot(gs[2, 6:])
    if not trajectories.empty:
        final_returns = trajectories.iloc[-1].dropna()
        ax_ret.hist(final_returns, bins=10, color='green', alpha=0.7, edgecolor='black')
        ax_ret.axvline(x=0, color='red', linestyle='--')
        ax_ret.set_xlabel('æ”¶ç›Šç‡ (%)')
        ax_ret.set_ylabel('æ•°é‡')
        ax_ret.set_title('ğŸ’° æ”¶ç›Šåˆ†å¸ƒ', fontsize=11)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=120, bbox_inches='tight')
    plt.close('all')
    print(f"âœ… å¢å¼ºç‰ˆTop10å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")


if __name__ == "__main__":
    print("=== Top10åˆ†æå™¨æµ‹è¯• ===")
    
    # æ¨¡æ‹ŸåŒ¹é…æ•°æ®
    matches = [
        {'symbol': '600519', 'date': '20231015', 'score': 0.95},
        {'symbol': '000858', 'date': '20230820', 'score': 0.92},
        {'symbol': '601318', 'date': '20231105', 'score': 0.89},
        {'symbol': '300750', 'date': '20230615', 'score': 0.87},
        {'symbol': '600036', 'date': '20230310', 'score': 0.85},
    ]
    
    analyzer = Top10Analyzer()
    stats = analyzer.analyze_matches(matches)
    
    print("\nç»Ÿè®¡åˆ†æç»“æœ:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    print("\n" + analyzer.create_stats_summary(stats))
