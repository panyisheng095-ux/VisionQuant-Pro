import os
import google.generativeai as genai
from dotenv import load_dotenv
import datetime

# åŠ è½½é…ç½®
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))
load_dotenv(os.path.join(PROJECT_ROOT, ".env"))

API_KEY = os.getenv("GOOGLE_API_KEY")


class AudioManager:
    def __init__(self):
        if not API_KEY:
            self.model = None
            print("âŒ [Audio] API Key ç¼ºå¤±")
            return

        genai.configure(api_key=API_KEY)

        # === æ ¸å¿ƒä¿®å¤ï¼šå®šä¹‰æ¨¡å‹å€™é€‰åˆ—è¡¨ ===
        # æ—¢ç„¶ä½ çš„ Agent èƒ½è¿ä¸Š 2.5-proï¼Œè¯´æ˜ä½ çš„å·å¾ˆæ–°
        # æˆ‘ä»¬ä¼˜å…ˆå°è¯•æ”¯æŒå¤šæ¨¡æ€çš„æ–°æ¨¡å‹
        self.candidate_models = [
            "gemini-2.0-flash-exp",  # æé€Ÿï¼Œæ”¯æŒéŸ³é¢‘
            "gemini-1.5-pro",  # ç¨³å®šï¼Œæ”¯æŒéŸ³é¢‘
            "gemini-1.5-flash",  # å¤‡é€‰
            "gemini-pro"  # å…œåº• (å¯èƒ½ä¸æ”¯æŒéŸ³é¢‘ï¼Œä½†å€¼å¾—ä¸€è¯•)
        ]

        print("ğŸ¤ [Audio] è¯­éŸ³å¼•æ“åˆå§‹åŒ–...")

    def transcribe(self, audio_bytes):
        """
        è¯­éŸ³è½¬æ–‡å­— (è‡ªåŠ¨è½®è¯¢æ¨¡å‹ç‰ˆ)
        """
        if not API_KEY: return None

        # 1. æ£€æŸ¥æ•°æ®å¤§å°
        data_size = len(audio_bytes)
        print(f"ğŸ¤ [Audio] æ”¶åˆ°æ•°æ®: {data_size} bytes")

        if data_size < 1000:
            print("âš ï¸ å½•éŸ³æ—¶é—´å¤ªçŸ­ï¼Œå¿½ç•¥")
            return None

        # 2. å¼ºåˆ¶ä¿å­˜è°ƒè¯•æ–‡ä»¶ (ä¿ç•™è¿™ä¸ªå¥½ä¹ æƒ¯)
        timestamp = datetime.datetime.now().strftime("%H%M%S")
        debug_path = os.path.join(PROJECT_ROOT, f"debug_audio_{timestamp}.wav")
        try:
            with open(debug_path, "wb") as f:
                f.write(audio_bytes)
        except:
            pass

        # 3. è½®è¯¢æ¨¡å‹è¿›è¡Œè¯†åˆ«
        prompt = "Please transcribe this audio to text. If Chinese, output Chinese directly. Do not translate. Output ONLY the text."

        for model_name in self.candidate_models:
            try:
                # åŠ¨æ€åˆå§‹åŒ–æ¨¡å‹
                model = genai.GenerativeModel(model_name)

                # print(f"   âŸ³ å°è¯•ä½¿ç”¨ {model_name} è¯†åˆ«...")

                response = model.generate_content([
                    prompt,
                    {"mime_type": "audio/wav", "data": audio_bytes}
                ])

                text = response.text.strip()
                if text:
                    print(f"âœ… [Audio] è¯†åˆ«æˆåŠŸ ({model_name}): {text}")
                    return text

            except Exception as e:
                # å¦‚æœæ˜¯ 404 Not Foundï¼Œè¯´æ˜è¿™ä¸ªæ¨¡å‹ä¸å¯ç”¨ï¼Œç›´æ¥è¯•ä¸‹ä¸€ä¸ª
                if "404" in str(e) or "not found" in str(e).lower():
                    continue
                else:
                    print(f"âŒ {model_name} æŠ¥é”™: {e}")
                    continue

        print("âŒ æ‰€æœ‰æ¨¡å‹å‡æ— æ³•è¯†åˆ«éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥ API Key æƒé™æˆ–ç½‘ç»œã€‚")
        return None