import os
import sys
import glob
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

# === 1. Mac ç³»ç»Ÿé˜²å´©é…ç½® ===
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

# === 2. è·¯å¾„é…ç½® ===
# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½• src/models
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
# è·å–é¡¹ç›®æ ¹ç›®å½• VisionQuant-Pro
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))
# å›¾ç‰‡è¯»å–è·¯å¾„
DATA_IMG_DIR = os.path.join(PROJECT_ROOT, "data", "images")
# æ¨¡å‹ä¿å­˜è·¯å¾„
MODEL_SAVE_DIR = os.path.join(PROJECT_ROOT, "data", "models")

# ç¡®ä¿èƒ½å¯¼å…¥ src ä¸‹çš„æ¨¡å—
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from src.models.autoencoder import QuantCAE

# === 3. è¶…å‚æ•°é…ç½® ===
BATCH_SIZE = 64  # ä¸€æ¬¡è®­ç»ƒ 64 å¼ å›¾ (M1/M2 èŠ¯ç‰‡å»ºè®® 64-128)
LEARNING_RATE = 1e-3  # å­¦ä¹ ç‡
EPOCHS = 5  # è®­ç»ƒè½®æ•° (Kçº¿å›¾æ¯”è¾ƒç®€å•ï¼Œ5è½®é€šå¸¸èƒ½æ”¶æ•›)


# ==========================================
#  æ•°æ®é›†åŠ è½½å™¨
# ==========================================
class KLineDataset(Dataset):
    def __init__(self, img_dir):
        print(f"ğŸ” æ­£åœ¨æ‰«æå›¾ç‰‡ç›®å½•: {img_dir} ...")
        # è·å–æ‰€æœ‰ png æ–‡ä»¶
        self.img_files = sorted(glob.glob(os.path.join(img_dir, "*.png")))
        print(f"ğŸ“¦ è®­ç»ƒé›†åŠ è½½å®Œæ¯•: å…±å‘ç° {len(self.img_files)} å¼  K çº¿å›¾")

        # é¢„å¤„ç†ï¼šè°ƒæ•´å¤§å° -> è½¬Tensor
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.img_files)

    def __getitem__(self, idx):
        try:
            img_path = self.img_files[idx]
            # å¿…é¡»è½¬ä¸º RGBï¼Œé˜²æ­¢éƒ¨åˆ†å›¾ç‰‡æ˜¯ RGBA
            img = Image.open(img_path).convert('RGB')
            return self.transform(img)
        except Exception as e:
            # å®¹é”™ï¼šå¦‚æœæŸå¼ å›¾åäº†ï¼Œè¿”å›å…¨é»‘å›¾ï¼Œé˜²æ­¢è®­ç»ƒä¸­æ–­
            return torch.zeros((3, 224, 224))


# ==========================================
#  æ ¸å¿ƒè®­ç»ƒæµç¨‹
# ==========================================
def train():
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

    # 1. è®¾å¤‡é€‰æ‹©
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("ğŸš€ [è®­ç»ƒ] ä½¿ç”¨ Apple Metal (MPS) æ˜¾å¡åŠ é€Ÿ")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("ğŸš€ [è®­ç»ƒ] ä½¿ç”¨ NVIDIA CUDA æ˜¾å¡åŠ é€Ÿ")
    else:
        device = torch.device("cpu")
        print("ğŸ¢ [è®­ç»ƒ] æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU (é€Ÿåº¦è¾ƒæ…¢)")

    # 2. å‡†å¤‡æ•°æ®
    dataset = KLineDataset(DATA_IMG_DIR)
    if len(dataset) == 0:
        print("âŒ é”™è¯¯: data/images ç›®å½•ä¸‹æ²¡æœ‰å›¾ç‰‡ï¼è¯·å…ˆè¿è¡Œ vision_engine ç”Ÿæˆå›¾ç‰‡ã€‚")
        return

    # num_workers=0 æ˜¯ Mac ä¸Šæœ€ç¨³çš„è®¾ç½®ï¼Œé˜²æ­¢å¤šè¿›ç¨‹æ­»é”
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)

    # 3. åˆå§‹åŒ–æ¨¡å‹
    model = QuantCAE().to(device)

    # æŸå¤±å‡½æ•°ï¼šå‡æ–¹è¯¯å·® (æ¯”è¾ƒ åŸå›¾ å’Œ è¿˜åŸå›¾ çš„åƒç´ å·®å¼‚)
    criterion = nn.MSELoss()
    # ä¼˜åŒ–å™¨ï¼šAdam
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    print(f"\nğŸ”¥ å¼€å§‹è®­ç»ƒ (è®¡åˆ’ {EPOCHS} è½®)...")
    print(f"ğŸ’¾ æ¨¡å‹å°†ä¿å­˜åœ¨: {MODEL_SAVE_DIR}")

    for epoch in range(EPOCHS):
        model.train()
        running_loss = 0.0

        # è¿›åº¦æ¡
        pbar = tqdm(dataloader, desc=f"Epoch {epoch + 1}/{EPOCHS}")

        for imgs in pbar:
            imgs = imgs.to(device)

            # --- A. å‰å‘ä¼ æ’­ ---
            # è¿™é‡Œçš„ labels å°±æ˜¯ imgs æœ¬èº«ï¼Œå› ä¸ºæ˜¯è‡ªç¼–ç å™¨
            encoded, decoded = model(imgs)

            # --- B. è®¡ç®—æŸå¤± ---
            loss = criterion(decoded, imgs)

            # --- C. åå‘ä¼ æ’­ ---
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # æ›´æ–°ç»Ÿè®¡
            running_loss += loss.item()
            pbar.set_postfix({"Loss": f"{loss.item():.6f}"})

        # è®¡ç®—æœ¬è½®å¹³å‡ Loss
        avg_loss = running_loss / len(dataloader)
        print(f"âœ… Epoch {epoch + 1} å®Œæˆ | å¹³å‡ Loss: {avg_loss:.6f}")

        # --- D. ä¿å­˜æ¨¡å‹ ---
        # ä¿å­˜ä¸¤ä¸ªç‰ˆæœ¬ï¼šæœ€æ–°ç‰ˆå’Œå½“å‰è½®æ¬¡ç‰ˆ
        save_path_latest = os.path.join(MODEL_SAVE_DIR, "cae_best.pth")
        save_path_epoch = os.path.join(MODEL_SAVE_DIR, f"cae_epoch_{epoch + 1}.pth")

        torch.save(model.state_dict(), save_path_latest)
        torch.save(model.state_dict(), save_path_epoch)
        print(f"ğŸ’¾ æ¨¡å‹å‚æ•°å·²ä¿å­˜")

    print("\nğŸ‰ è®­ç»ƒå…¨éƒ¨å®Œæˆï¼æ–°å¤§è„‘å·²å°±ç»ªã€‚")


if __name__ == "__main__":
    train()