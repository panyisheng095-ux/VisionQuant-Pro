"""
å› å­æœ‰æ•ˆæ€§åˆ†ææŠ¥å‘Šç”Ÿæˆæ¨¡å—
Factor Effectiveness Analysis Report Generator

æ•´åˆæ‰€æœ‰åˆ†ææ¨¡å—ï¼Œç”Ÿæˆå®Œæ•´çš„å› å­æœ‰æ•ˆæ€§æŠ¥å‘Š

Author: VisionQuant Team
"""

import pandas as pd
import numpy as np
from typing import Dict, Optional, List
from datetime import datetime
import json

from .ic_analysis import ICAnalyzer
from .regime_detector import RegimeDetector, MarketRegime
from .decay_analysis import DecayAnalyzer
from .crowding_detector import CrowdingDetector
from .risk_compensation import RiskCompensationAnalyzer
from .industry_stratification import IndustryStratifier
from .factor_invalidation import FactorInvalidationDetector


class FactorReportGenerator:
    """
    å› å­æœ‰æ•ˆæ€§åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
    
    æ•´åˆæ‰€æœ‰åˆ†ææ¨¡å—ï¼Œç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
        self.ic_analyzer = ICAnalyzer(window=252)
        self.regime_detector = RegimeDetector()
        self.decay_analyzer = DecayAnalyzer()
        self.crowding_detector = CrowdingDetector()
        self.risk_analyzer = RiskCompensationAnalyzer()
        self.industry_stratifier = IndustryStratifier()
        self.invalidation_detector = FactorInvalidationDetector()
    
    def generate_report(
        self,
        factor_values: pd.Series,
        returns: pd.Series,
        prices: pd.Series = None,
        factor_exposures: pd.DataFrame = None,
        industry_mapping: Dict[str, str] = None
    ) -> Dict:
        """
        ç”Ÿæˆå®Œæ•´çš„å› å­æœ‰æ•ˆæ€§åˆ†ææŠ¥å‘Š
        
        Args:
            factor_values: å› å­å€¼åºåˆ—
            returns: æœªæ¥æ”¶ç›Šç‡åºåˆ—
            prices: ä»·æ ¼åºåˆ—ï¼ˆå¯é€‰ï¼Œç”¨äºRegimeè¯†åˆ«ï¼‰
            factor_exposures: å› å­æš´éœ²åº¦DataFrameï¼ˆå¯é€‰ï¼Œç”¨äºæ‹¥æŒ¤æ£€æµ‹ï¼‰
            industry_mapping: è¡Œä¸šæ˜ å°„ï¼ˆå¯é€‰ï¼Œç”¨äºè¡Œä¸šåˆ†æï¼‰
            
        Returns:
            å®Œæ•´åˆ†ææŠ¥å‘Šå­—å…¸
        """
        report = {
            'report_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'factor_name': 'Kçº¿å­¦ä¹ å› å­',
            'analysis_period': {
                'start': str(factor_values.index[0]),
                'end': str(factor_values.index[-1]),
                'total_days': len(factor_values)
            }
        }
        
        # 1. ICåˆ†æ
        print("ğŸ“Š è¿›è¡ŒICåˆ†æ...")
        ic_result = self.ic_analyzer.analyze(factor_values, returns)
        report['ic_analysis'] = {
            'summary': ic_result['summary'],
            'ic_series': ic_result['ic_series'].to_dict() if hasattr(ic_result['ic_series'], 'to_dict') else None,
            'sharpe_series': ic_result['sharpe_series'].to_dict() if hasattr(ic_result['sharpe_series'], 'to_dict') else None
        }
        
        # 2. Regimeåˆ†æ
        print("ğŸ“ˆ è¿›è¡ŒRegimeè¯†åˆ«...")
        regimes = self.regime_detector.detect_regime(returns, prices)
        regime_stats = self.regime_detector.get_regime_statistics(regimes, returns)
        report['regime_analysis'] = {
            'regime_distribution': regime_stats['regime_distribution'],
            'regime_returns': {k: v for k, v in regime_stats.items() if k.endswith('_returns')}
        }
        
        # 3. è¡°å‡åˆ†æ
        print("ğŸ“‰ è¿›è¡Œè¡°å‡åˆ†æ...")
        ic_series = ic_result['ic_series']
        decay_result = self.decay_analyzer.analyze_decay(ic_series)
        report['decay_analysis'] = {
            'is_decaying': decay_result['is_decaying'],
            'decay_start_date': str(decay_result['decay_start_date']) if decay_result['decay_start_date'] else None,
            'decay_rate': decay_result['decay_rate'],
            'predicted_invalidation_date': str(decay_result['predicted_invalidation_date']) if decay_result['predicted_invalidation_date'] else None
        }
        
        # 4. æ‹¥æŒ¤æ£€æµ‹
        if factor_exposures is not None:
            print("ğŸ” è¿›è¡Œæ‹¥æŒ¤æ£€æµ‹...")
            crowding_result = self.crowding_detector.detect_crowding(factor_exposures)
            report['crowding_analysis'] = {
                'is_crowded': crowding_result['is_crowded'],
                'concentration': crowding_result['concentration'],
                'herfindahl_index': crowding_result['herfindahl_index'],
                'crowding_score': crowding_result['crowding_score']
            }
        else:
            report['crowding_analysis'] = None
        
        # 5. é£é™©è¡¥å¿åˆ†æ
        print("ğŸ’° è¿›è¡Œé£é™©è¡¥å¿åˆ†æ...")
        risk_result = self.risk_analyzer.analyze_risk_compensation(returns, factor_values)
        report['risk_compensation'] = {
            'overall_metrics': risk_result['overall_metrics'],
            'quantile_metrics': risk_result['quantile_metrics']
        }
        
        # 6. è¡Œä¸šåˆ†æ
        if industry_mapping is not None:
            print("ğŸ­ è¿›è¡Œè¡Œä¸šåˆ†æ...")
            # éœ€è¦å°†factor_valueså’Œreturnsè½¬æ¢ä¸ºDataFrameæ ¼å¼
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ®æ•°æ®æ ¼å¼è°ƒæ•´
            try:
                # å‡è®¾factor_valueså’Œreturnsæ˜¯å•è‚¡ç¥¨çš„åºåˆ—
                # å®é™…åº”è¯¥ä¼ å…¥å¤šè‚¡ç¥¨çš„DataFrame
                report['industry_analysis'] = {
                    'note': 'è¡Œä¸šåˆ†æéœ€è¦å¤šè‚¡ç¥¨æ•°æ®ï¼Œå½“å‰ä¸ºå•è‚¡ç¥¨åºåˆ—'
                }
            except:
                report['industry_analysis'] = None
        else:
            report['industry_analysis'] = None
        
        # 7. å¤±æ•ˆæ£€æµ‹
        print("âš ï¸ è¿›è¡Œå¤±æ•ˆæ£€æµ‹...")
        invalidation_result = self.invalidation_detector.detect_invalidation(
            factor_values, returns, factor_exposures
        )
        report['invalidation_detection'] = {
            'is_invalidated': invalidation_result['is_invalidated'],
            'invalidation_score': invalidation_result['invalidation_score'],
            'dimensions': invalidation_result['dimensions'],
            'warning': self.invalidation_detector.get_invalidation_warning(invalidation_result)
        }
        
        # 8. ç»¼åˆè¯„ä¼°
        report['overall_assessment'] = self._generate_overall_assessment(report)
        
        return report
    
    def _generate_overall_assessment(self, report: Dict) -> Dict:
        """
        ç”Ÿæˆç»¼åˆè¯„ä¼°
        """
        assessment = {
            'factor_quality': 'Unknown',
            'recommendation': 'Unknown',
            'key_strengths': [],
            'key_weaknesses': [],
            'risk_level': 'Medium'
        }
        
        # è¯„ä¼°å› å­è´¨é‡
        ic_mean = report['ic_analysis']['summary'].get('mean_ic', 0)
        ic_ir = report['ic_analysis']['summary'].get('ir', 0)
        is_significant = report['ic_analysis']['summary'].get('significant', False)
        
        if ic_mean > 0.05 and ic_ir > 1.0 and is_significant:
            assessment['factor_quality'] = 'Excellent'
        elif ic_mean > 0.03 and ic_ir > 0.5:
            assessment['factor_quality'] = 'Good'
        elif ic_mean > 0.01:
            assessment['factor_quality'] = 'Fair'
        else:
            assessment['factor_quality'] = 'Poor'
        
        # è¯†åˆ«ä¼˜åŠ¿
        if ic_mean > 0.03:
            assessment['key_strengths'].append('ICè¡¨ç°è‰¯å¥½')
        if ic_ir > 0.5:
            assessment['key_strengths'].append('ä¿¡æ¯æ¯”ç‡è¾ƒé«˜')
        if report['risk_compensation']['overall_metrics']['sharpe_ratio'] > 1.0:
            assessment['key_strengths'].append('é£é™©è°ƒæ•´æ”¶ç›Šä¼˜ç§€')
        
        # è¯†åˆ«åŠ£åŠ¿
        if report['decay_analysis']['is_decaying']:
            assessment['key_weaknesses'].append('å› å­å‡ºç°è¡°å‡')
        if report['invalidation_detection']['is_invalidated']:
            assessment['key_weaknesses'].append('å› å­å¯èƒ½å¤±æ•ˆ')
        if report.get('crowding_analysis') and report['crowding_analysis']['is_crowded']:
            assessment['key_weaknesses'].append('æ£€æµ‹åˆ°æ‹¥æŒ¤äº¤æ˜“')
        
        # æ¨èå»ºè®®
        if assessment['factor_quality'] in ['Excellent', 'Good']:
            assessment['recommendation'] = 'å»ºè®®ç»§ç»­ä½¿ç”¨'
        elif assessment['factor_quality'] == 'Fair':
            assessment['recommendation'] = 'å»ºè®®è°¨æ…ä½¿ç”¨ï¼ŒæŒç»­ç›‘æ§'
        else:
            assessment['recommendation'] = 'å»ºè®®æš‚åœä½¿ç”¨æˆ–é™ä½æƒé‡'
        
        # é£é™©ç­‰çº§
        if report['invalidation_detection']['invalidation_score'] > 0.7:
            assessment['risk_level'] = 'High'
        elif report['invalidation_detection']['invalidation_score'] > 0.4:
            assessment['risk_level'] = 'Medium'
        else:
            assessment['risk_level'] = 'Low'
        
        return assessment
    
    def export_report(
        self,
        report: Dict,
        output_path: str,
        format: str = 'json'
    ):
        """
        å¯¼å‡ºæŠ¥å‘Š
        
        Args:
            report: æŠ¥å‘Šå­—å…¸
            output_path: è¾“å‡ºè·¯å¾„
            format: æ ¼å¼ ('json', 'csv', 'html')
        """
        if format == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        elif format == 'csv':
            # å¯¼å‡ºå…³é”®æŒ‡æ ‡åˆ°CSV
            summary_data = {
                'æŒ‡æ ‡': [
                    'å¹³å‡IC', 'ICæ ‡å‡†å·®', 'ä¿¡æ¯æ¯”ç‡', 'å¹³å‡Sharpe',
                    'æ˜¯å¦è¡°å‡', 'æ˜¯å¦å¤±æ•ˆ', 'å› å­è´¨é‡'
                ],
                'æ•°å€¼': [
                    report['ic_analysis']['summary']['mean_ic'],
                    report['ic_analysis']['summary']['std_ic'],
                    report['ic_analysis']['summary']['ir'],
                    report['risk_compensation']['overall_metrics']['sharpe_ratio'],
                    report['decay_analysis']['is_decaying'],
                    report['invalidation_detection']['is_invalidated'],
                    report['overall_assessment']['factor_quality']
                ]
            }
            df = pd.DataFrame(summary_data)
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")


if __name__ == "__main__":
    print("=== å› å­æŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯• ===")
    
    # æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', periods=500, freq='D')
    factor_values = pd.Series(np.random.randn(500).cumsum(), index=dates)
    returns = pd.Series(np.random.randn(500) * 0.01, index=dates)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = FactorReportGenerator()
    report = generator.generate_report(factor_values, returns)
    
    print(f"\næŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print(f"å› å­è´¨é‡: {report['overall_assessment']['factor_quality']}")
    print(f"æ¨èå»ºè®®: {report['overall_assessment']['recommendation']}")
