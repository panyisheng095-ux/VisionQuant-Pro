# 因子分析性能优化说明

## 为什么600个样本要算这么久？

### 耗时原因分析

每个样本点（600个中的每一个）都需要执行以下操作：

#### 1. **FAISS向量搜索**（主要瓶颈）
- **操作**：在100万条记录的FAISS索引中搜索相似图像
- **耗时**：即使使用`fast_mode`，每次搜索也需要 **100-500ms**
- **原因**：
  - 需要将查询图像编码为1024维向量（CNN推理）
  - 在100万条记录中搜索top_k=500的候选（向量相似度计算）
  - 即使fast_mode跳过了DTW/相关性计算，向量搜索本身也需要时间

#### 2. **数据加载**（次要瓶颈）
- **操作**：`calculate_hybrid_win_rate` 对每个match（10个）都要调用 `data_loader.get_stock_data(symbol)`
- **耗时**：如果缓存未命中，每次从磁盘读取CSV需要 **50-200ms**
- **原因**：
  - 需要读取历史价格数据计算Triple Barrier标签
  - 需要读取未来收益率计算传统胜率
  - 如果缓存未命中，需要从磁盘读取CSV文件

#### 3. **胜率计算**（次要瓶颈）
- **操作**：对每个match计算Triple Barrier胜率和传统胜率
- **耗时**：每个match需要 **10-50ms**（取决于数据是否在缓存中）
- **原因**：
  - Triple Barrier计算：需要获取未来20天的价格数据
  - 传统胜率计算：需要计算未来5日收益率
  - 如果HDF5中没有标签，需要实时计算

### 性能估算

| 场景 | 每个样本耗时 | 600个样本总耗时 |
|------|------------|---------------|
| **理想情况**（所有数据在缓存） | 600ms | 6分钟 |
| **实际情况**（部分数据需要从磁盘加载） | 1200ms | 12分钟 |
| **最坏情况**（大量数据需要从磁盘加载） | 3500ms | 35分钟 |

**实际观察**：20-30分钟，说明大部分数据需要从磁盘加载，缓存命中率较低。

## 优化方案

### 已实施的优化

#### 1. **减少样本数**
- 从600降到200（兼顾速度和科学性）
- 使用自适应步长，数据越长步长越大

#### 2. **启用快速模式**
- `fast_mode=True`：跳过DTW/相关性计算
- `search_k=300`：减少搜索范围（从500降到300）
- `top_k=5`：减少match数量（从10降到5）
- `max_price_checks=30`：限制价格检查次数

#### 3. **跳过enhanced_factor计算**
- 因子分析不需要enhanced_factor（分布估计、情境感知等）
- 设置 `query_df=None`，跳过enhanced_factor计算
- **节省时间**：每个样本节省约200-500ms

#### 4. **优化回退方案**
- 减少窗口数量（从200降到100）
- 使用点积计算相关性（比`corrcoef`快）

#### 5. **数据加载器缓存**
- `mem_cache_max=128`：内存缓存128个股票的数据
- 减少重复从磁盘读取

### 预期性能提升

| 优化项 | 优化前 | 优化后 | 提升 |
|--------|--------|--------|------|
| 样本数 | 600 | 200 | 3x |
| top_k | 10 | 5 | 2x |
| search_k | 500 | 300 | 1.7x |
| enhanced_factor | 计算 | 跳过 | 2-3x |
| **总耗时** | **20-30分钟** | **2-5分钟** | **10x** |

## 进一步优化建议（如果还需要更快）

### 1. **批量处理**
- 一次性处理多个样本，减少重复的FAISS搜索
- 使用批量图像编码（batch encoding）

### 2. **预加载数据**
- 提前分析可能用到的股票代码，预加载到内存
- 使用多线程并行加载

### 3. **并行计算**
- 使用多进程/多线程并行计算多个样本
- 注意：FAISS索引是共享的，需要线程安全

### 4. **缓存优化**
- 增加DataLoader的缓存大小（从128到256或更大）
- 使用Redis等外部缓存存储常用股票数据

### 5. **减少FAISS搜索范围**
- 如果精度要求不高，可以进一步减少`search_k`（从300降到200）
- 或者使用更快的FAISS索引类型（如IVF）

## 总结

**为什么600个样本要算这么久？**

1. **FAISS搜索是主要瓶颈**：在100万条记录中搜索，每次100-500ms
2. **数据加载是次要瓶颈**：如果缓存未命中，需要从磁盘读取CSV
3. **重复计算**：每个样本都要重新搜索和计算，没有批量优化

**优化后的预期效果**：
- 从20-30分钟降低到 **2-5分钟**
- 通过减少样本数、启用快速模式、跳过不必要计算等方式，实现 **10倍性能提升**

**如果还需要更快**：
- 可以考虑批量处理、并行计算、预加载数据等方案
- 但需要权衡精度和速度
