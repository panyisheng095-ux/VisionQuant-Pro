"""å› å­åˆ†æå¤„ç†æ¨¡å— - å·¥ä¸šçº§ä¼˜åŒ–"""
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import os
import logging
import mplfinance as mpf
from multiprocessing import cpu_count
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def show_factor_analysis(symbol, df_f, eng, PROJECT_ROOT):
    """
    å› å­æœ‰æ•ˆæ€§åˆ†æ

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        df_f: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„DataFrame
        eng: å¼•æ“å­—å…¸
        PROJECT_ROOT: é¡¹ç›®æ ¹ç›®å½•
    """
    import streamlit as st

    try:
        logger.info(f"å¼€å§‹å› å­åˆ†æ: {symbol}")
        # å·¥ä¸šçº§å¹¶è¡Œä¼˜åŒ–æç¤º
        with st.spinner("ğŸš€ æ­£åœ¨è®¡ç®—å› å­å€¼ï¼ˆå·¥ä¸šçº§å¹¶è¡Œä¼˜åŒ–ï¼Œ600æ ·æœ¬ï¼Œé¢„è®¡1-3åˆ†é’Ÿï¼‰..."):
            from src.factor_analysis.ic_analysis import ICAnalyzer
            from src.factor_analysis.regime_detector import RegimeDetector
            from src.strategies.kline_factor import KLineFactorCalculator
            from src.factor_analysis.factor_invalidation import FactorInvalidationDetector

            kline_calc = KLineFactorCalculator(data_loader=eng.get("loader"))
            factor_values, forward_returns, dates, horizon_returns, success_count, fail_count = _calculate_factor_values(
                df_f, symbol, kline_calc, eng["vision"], PROJECT_ROOT, horizons=[1, 5, 10, 20]
            )

        if len(factor_values) < 20:
            st.warning(f"æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘20ä¸ªæœ‰æ•ˆæ•°æ®ç‚¹ï¼ˆå½“å‰ {len(factor_values)}ï¼‰")
            st.caption(f"åŒ¹é…è¯Šæ–­: å°è¯• {success_count + fail_count} æ¬¡ | æˆåŠŸ {success_count} æ¬¡ | å¤±è´¥ {fail_count} æ¬¡")
            if fail_count > success_count:
                st.info("ğŸ’¡ å¤±è´¥ç‡è¿‡é«˜æç¤ºï¼šå½“å‰å›¾åº“å¯¹è¯¥è‚¡å†å²å½¢æ€çš„è¦†ç›–åº¦ä¸è¶³ã€‚å»ºè®®æ‰©å……å›¾åº“è‡³100ä¸‡æ ·æœ¬ã€‚")
            logger.warning(f"å› å­åˆ†ææ•°æ®ä¸è¶³: {symbol}, æœ‰æ•ˆç‚¹æ•°: {len(factor_values)}")
            return

        # æ ·æœ¬é‡ç½®ä¿¡åº¦æç¤ºï¼ˆç§‘å­¦æ€§ï¼‰
        n = len(factor_values)
        if n >= 500:
            conf = "é«˜"
        elif n >= 200:
            conf = "ä¸­"
        elif n >= 80:
            conf = "ä½"
        else:
            conf = "åä½"
        st.caption(f"æœ‰æ•ˆæ ·æœ¬æ•°: {n} | ç½®ä¿¡åº¦: {conf}")
        total_attempts = success_count + fail_count
        fail_rate = (fail_count / total_attempts * 100) if total_attempts > 0 else 0.0
        st.caption(f"åŒ¹é…è¯Šæ–­: å°è¯• {total_attempts} æ¬¡ | æˆåŠŸ {success_count} æ¬¡ | å¤±è´¥ {fail_count} æ¬¡ (å¤±è´¥ç‡ {fail_rate:.1f}%)")

        factor_series = pd.Series(factor_values, index=pd.to_datetime(dates))
        returns_series = pd.Series(forward_returns, index=pd.to_datetime(dates))

        # ---- ICAnalyzer æ­£ç¡®ç”¨æ³•ï¼š__init__(window=...) + analyze(factor_values, returns) ----
        # é€‰æ‹©ä¸€ä¸ªä¸ä¼šå¯¼è‡´ç©ºåºåˆ—çš„çª—å£ï¼š20~60ä¹‹é—´ï¼Œä¸”ä¸¥æ ¼å°äºæ ·æœ¬é•¿åº¦
        n = len(factor_series)
        window = min(60, max(20, n // 2))
        window = min(window, max(2, n - 1))
        ic_analyzer = ICAnalyzer(window=window)
        # v3.0: å¼€å¯ç¨³å¥ç»Ÿè®¡ (Winsorization)
        ic_result = ic_analyzer.analyze(factor_series, returns_series, method="pearson")
        # ç¼“å­˜ICæ‘˜è¦ï¼Œä¾›AIç»ˆå®¡ä½¿ç”¨
        try:
            summary = ic_result.get("summary", {})
            payload = {
                "mean_ic": summary.get("mean_ic"),
                "ir": summary.get("ir"),
                "positive_ratio": summary.get("positive_ratio"),
                "significant": summary.get("significant"),
                "samples": len(factor_series),
            }
            if "ic_summary" not in st.session_state:
                st.session_state.ic_summary = {}
            st.session_state.ic_summary[symbol] = payload
        except Exception:
            pass
        # å¤šæŒæœ‰æœŸICçŸ©é˜µ
        try:
            horizon_series = {}
            for h, ret_list in horizon_returns.items():
                if len(ret_list) != len(dates):
                    continue
                horizon_series[h] = pd.Series(ret_list, index=pd.to_datetime(dates))
            multi_ic = ic_analyzer.analyze_multi_horizon(factor_series, horizon_series, method="pearson")
        except Exception:
            multi_ic = {}
        rolling_ic = ic_result.get("ic_series", pd.Series(dtype=float))

        _plot_ic_curve(rolling_ic, ic_result)
        if multi_ic:
            _plot_ic_horizon_matrix(multi_ic)
        _plot_sharpe_curve(ic_result)
        _plot_regime_distribution(df_f)

        # è¡°å‡ + æ‹ç‚¹æ£€æµ‹ï¼ˆChange Point / CUSUMï¼‰
        try:
            from src.factor_analysis.decay_analysis import DecayAnalyzer
            decay_analyzer = DecayAnalyzer()
            decay_result = decay_analyzer.analyze_decay(rolling_ic)
        except Exception:
            decay_result = {}

        _plot_decay_analysis(rolling_ic, decay_result)
        _detect_invalidation(factor_series, returns_series)

    except ImportError as e:
        logger.exception(f"å› å­åˆ†ææ¨¡å—å¯¼å…¥å¤±è´¥: {symbol}")
        st.error(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    except Exception as e:
        logger.exception(f"å› å­åˆ†æå¼‚å¸¸: {symbol}")
        st.error(f"å› å­åˆ†æå¤±è´¥: {e}")
        import traceback
        with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
            st.code(traceback.format_exc())


def _calculate_factor_values(df_f, symbol, kline_calc, vision_engine, PROJECT_ROOT, horizons=None, use_parallel=True):
    """
    è®¡ç®—å†å²å› å­å€¼ï¼ˆå·¥ä¸šçº§å¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰

    é€šè¿‡éå†å†å²æ•°æ®ï¼Œä¸ºæ¯ä¸ªæ—¶é—´ç‚¹è®¡ç®—Kçº¿å­¦ä¹ å› å­å€¼
    ä¼˜åŒ–ï¼šå¤šè¿›ç¨‹å¹¶è¡Œã€æ‰¹é‡å¤„ç†ã€é¢„åŠ è½½æ•°æ®ã€ä¿æŒ600æ ·æœ¬é‡
    """
    import streamlit as st
    from multiprocessing import Pool, cpu_count
    from functools import partial
    
    if horizons is None:
        horizons = [1, 5, 10, 20]
    factor_values, forward_returns, dates = [], [], []
    horizon_returns = {h: [] for h in horizons}

    # è¦†ç›–å…¨åŒºé—´ + ä¿æŒ600æ ·æœ¬é‡ï¼ˆå·¥ä¸šçº§è¦æ±‚ï¼‰
    end_idx = len(df_f) - 6  # éœ€è¦ i+5 å¯å–
    if end_idx <= 20:
        return factor_values, forward_returns, dates, horizon_returns, 0, 0

    total_points = end_idx - 20 + 1
    # å·¥ä¸šçº§ï¼šä¿æŒ600æ ·æœ¬é‡ï¼Œé€šè¿‡å¹¶è¡Œè®¡ç®—åŠ é€Ÿ
    target_points = min(600, total_points)
    # è‡ªé€‚åº”æ­¥é•¿ï¼šæ•°æ®è¶Šé•¿ï¼Œæ­¥é•¿è¶Šå¤§
    if total_points <= 600:
        step = 1
    elif total_points <= 1200:
        step = 2
    elif total_points <= 2400:
        step = 4
    else:
        step = max(1, total_points // target_points)
    sample_idx = list(range(20, end_idx + 1, step))
    # å…œåº•é¿å…è¿‡å¤š
    if len(sample_idx) > target_points:
        sample_idx = sample_idx[:target_points]

    # å·¥ä¸šçº§ä¼˜åŒ–ï¼šé¢„åŠ è½½æ•°æ®åˆ°å†…å­˜ï¼Œé¿å…é‡å¤I/O
    logger.info(f"é¢„åŠ è½½æ•°æ®ï¼šåˆ†æå¯èƒ½ç”¨åˆ°çš„è‚¡ç¥¨ä»£ç ...")
    potential_symbols = set()
    for i in sample_idx:
        # ä»å†å²æ•°æ®ä¸­æå–å¯èƒ½ç”¨åˆ°çš„è‚¡ç¥¨ä»£ç ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…å¯ä»¥ä»matchesä¸­æå–ï¼‰
        potential_symbols.add(symbol)
    # é¢„åŠ è½½å½“å‰è‚¡ç¥¨çš„æ‰€æœ‰æ•°æ®ï¼ˆå·²ç»åœ¨df_fä¸­ï¼Œä½†ç¡®ä¿DataLoaderç¼“å­˜ï¼‰
    if kline_calc.data_loader:
        try:
            kline_calc.data_loader.get_stock_data(symbol, use_cache=True)
        except:
            pass
    
    success_count = 0
    fail_count = 0
    
    # æ·»åŠ è¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    total_iters = len(sample_idx)
    
    # å·¥ä¸šçº§ä¼˜åŒ–ï¼šä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼ˆFAISSå’ŒPyTorchå¯ä»¥é‡Šæ”¾GILï¼‰
    if use_parallel and total_iters > 50:
        # ç¡®å®šçº¿ç¨‹æ•°ï¼ˆä¸è¶…è¿‡CPUæ ¸å¿ƒæ•°ï¼Œä½†è€ƒè™‘åˆ°I/Oç­‰å¾…ï¼Œå¯ä»¥æ›´å¤šï¼‰
        max_workers = min(cpu_count() * 2, 16, total_iters)
        logger.info(f"ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼š{max_workers}ä¸ªçº¿ç¨‹ï¼Œ{total_iters}ä¸ªæ ·æœ¬")
        
        # çº¿ç¨‹å®‰å…¨çš„è®¡æ•°å™¨
        completed_count = threading.Lock()
        completed = [0]
        results = []
        
        def process_single_sample(i):
            """å¤„ç†å•ä¸ªæ ·æœ¬ç‚¹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
            try:
                current_data = df_f.iloc[i-20:i]
                if len(current_data) < 20:
                    return None

                date_dt = df_f.index[i]
                date_str = _safe_date_str(date_dt)
                
                # ç”Ÿæˆä¸´æ—¶å›¾åƒ
                temp_img = os.path.join(PROJECT_ROOT, "data", f"temp_factor_{i}_{threading.current_thread().ident}.png")
                mc = mpf.make_marketcolors(up='red', down='green', inherit=True)
                s = mpf.make_mpf_style(marketcolors=mc, gridstyle='')
                mpf.plot(current_data, type='candle', style=s, savefig=dict(fname=temp_img, dpi=50),
                        figsize=(3, 3), axisoff=True)

                # å¿«é€Ÿæ¨¡å¼æœç´¢
                matches = vision_engine.search_similar_patterns(
                    temp_img, 
                    top_k=5,
                    max_date=date_dt,
                    fast_mode=True,
                    search_k=300,
                    rerank_with_pixels=False,
                    max_price_checks=30,
                    use_price_features=False
                )

                # å›é€€æ–¹æ¡ˆ
                if not matches or len(matches) < 3:
                    matches = _self_match_windows(df_f, symbol, i, top_k=5)

                if matches and len(matches) > 0:
                    try:
                        factor_result = kline_calc.calculate_hybrid_win_rate(
                            matches,
                            query_symbol=symbol,
                            query_date=date_str,
                            query_df=None
                        )
                        if isinstance(factor_result, dict):
                            enhanced = factor_result.get("enhanced_factor")
                            if isinstance(enhanced, dict) and enhanced.get("final_score") is not None:
                                factor_value = float(enhanced.get("final_score")) / 100.0
                            else:
                                factor_value = factor_result.get('hybrid_win_rate', 50.0) / 100.0
                        else:
                            factor_value = 0.5

                        # å¤šæŒæœ‰æœŸæ”¶ç›Šç‡
                        p_entry = df_f.iloc[i]['Close']
                        rets = {}
                        for h in horizons:
                            if i + h < len(df_f):
                                p_exit = df_f.iloc[i + h]['Close']
                                rets[h] = (p_exit - p_entry) / p_entry
                        p_exit = df_f.iloc[i+5]['Close'] if i + 5 < len(df_f) else df_f.iloc[i]['Close']
                        ret = (p_exit - p_entry) / p_entry

                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if os.path.exists(temp_img):
                            os.remove(temp_img)
                        
                        return {
                            'success': True,
                            'factor_value': factor_value,
                            'forward_return': ret,
                            'date': date_str,
                            'horizon_returns': rets
                        }
                    except Exception as e:
                        logger.warning(f"è®¡ç®—å› å­å€¼å¤±è´¥: {i}, {e}")
                        if os.path.exists(temp_img):
                            os.remove(temp_img)
                        return {'success': False}
                else:
                    if os.path.exists(temp_img):
                        os.remove(temp_img)
                    return {'success': False}
            except Exception as e:
                logger.warning(f"å¤„ç†æ ·æœ¬å¤±è´¥: {i}, {e}")
                return {'success': False}
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_idx = {executor.submit(process_single_sample, i): i for i in sample_idx}
            
            # æ”¶é›†ç»“æœå¹¶æ›´æ–°è¿›åº¦
            for future in as_completed(future_to_idx):
                result = future.result()
                if result and result.get('success'):
                    success_count += 1
                    factor_values.append(result['factor_value'])
                    forward_returns.append(result['forward_return'])
                    dates.append(result['date'])
                    for h, ret in result.get('horizon_returns', {}).items():
                        horizon_returns[h].append(ret)
                else:
                    fail_count += 1
                
                # æ›´æ–°è¿›åº¦
                with completed_count:
                    completed[0] += 1
                    progress = completed[0] / total_iters
                    progress_bar.progress(progress)
                    status_text.text(f"è®¡ç®—å› å­å€¼: {completed[0]}/{total_iters} ({progress*100:.1f}%)")
    else:
        # ä¸²è¡Œå¤„ç†ï¼ˆå°æ ·æœ¬é‡æˆ–ç¦ç”¨å¹¶è¡Œæ—¶ï¼‰
        for idx, i in enumerate(sample_idx):
            try:
                current_data = df_f.iloc[i-20:i]
                if len(current_data) < 20:
                    continue

                date_dt = df_f.index[i]
                date_str = _safe_date_str(date_dt)

                # æ›´æ–°è¿›åº¦
                progress = (idx + 1) / total_iters
                progress_bar.progress(progress)
                status_text.text(f"è®¡ç®—å› å­å€¼: {idx + 1}/{total_iters} ({progress*100:.1f}%)")
                
                temp_img = os.path.join(PROJECT_ROOT, "data", f"temp_factor_{i}.png")
                mc = mpf.make_marketcolors(up='red', down='green', inherit=True)
                s = mpf.make_mpf_style(marketcolors=mc, gridstyle='')
                mpf.plot(current_data, type='candle', style=s, savefig=dict(fname=temp_img, dpi=50),
                        figsize=(3, 3), axisoff=True)

                matches = vision_engine.search_similar_patterns(
                    temp_img, 
                    top_k=5,
                    max_date=date_dt,
                    fast_mode=True,
                    search_k=300,
                    rerank_with_pixels=False,
                    max_price_checks=30,
                    use_price_features=False
                )

                if not matches or len(matches) < 3:
                    matches = _self_match_windows(df_f, symbol, i, top_k=5)

                if matches and len(matches) > 0:
                    success_count += 1
                    try:
                        factor_result = kline_calc.calculate_hybrid_win_rate(
                            matches,
                            query_symbol=symbol,
                            query_date=date_str,
                            query_df=None
                        )
                        if isinstance(factor_result, dict):
                            enhanced = factor_result.get("enhanced_factor")
                            if isinstance(enhanced, dict) and enhanced.get("final_score") is not None:
                                factor_value = float(enhanced.get("final_score")) / 100.0
                            else:
                                factor_value = factor_result.get('hybrid_win_rate', 50.0) / 100.0
                        else:
                            factor_value = 0.5

                        p_entry = df_f.iloc[i]['Close']
                        for h in horizons:
                            if i + h < len(df_f):
                                p_exit = df_f.iloc[i + h]['Close']
                                ret = (p_exit - p_entry) / p_entry
                                horizon_returns[h].append(ret)
                        p_exit = df_f.iloc[i+5]['Close'] if i + 5 < len(df_f) else df_f.iloc[i]['Close']
                        ret = (p_exit - p_entry) / p_entry

                        factor_values.append(factor_value)
                        forward_returns.append(ret)
                        dates.append(date_str)

                    except Exception:
                        pass
                else:
                    fail_count += 1

                if os.path.exists(temp_img):
                    os.remove(temp_img)

            except Exception:
                fail_count += 1
                continue
    
    # æ¸…ç†è¿›åº¦æ¡
    progress_bar.empty()
    status_text.empty()

    return factor_values, forward_returns, dates, horizon_returns, success_count, fail_count


def _self_match_windows(df_f, symbol, idx, window: int = 20, top_k: int = 10, max_windows: int = 100):
    """
    å›é€€æ–¹æ¡ˆï¼šä»…åœ¨"åŒä¸€è‚¡ç¥¨å†å²çª—å£"å†…åšå½¢æ€ç›¸ä¼¼åº¦ï¼ˆæ— æœªæ¥å‡½æ•°ï¼‰
    æ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘æœ€å¤§çª—å£æ•°ï¼Œä½¿ç”¨æ›´å¿«çš„ç›¸å…³æ€§è®¡ç®—
    """
    try:
        if idx <= window:
            return []
        q_prices = df_f.iloc[idx - window: idx]["Close"].values
        if len(q_prices) < window:
            return []

        # æ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘çª—å£æ•°é‡ï¼ˆä»200é™åˆ°100ï¼‰
        start = window
        end = idx
        total = end - start
        if total <= 0:
            return []
        step = max(1, total // max_windows)

        # æ€§èƒ½ä¼˜åŒ–ï¼šé¢„è®¡ç®—å½’ä¸€åŒ–æŸ¥è¯¢ä»·æ ¼
        q_mean = q_prices.mean()
        q_std = q_prices.std() + 1e-8
        q_norm = (q_prices - q_mean) / q_std
        
        candidates = []
        for j in range(start, end, step):
            cand = df_f.iloc[j - window: j]["Close"].values
            if len(cand) < window:
                continue
            # æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨æ›´å¿«çš„ç›¸å…³æ€§è®¡ç®—
            c_mean = cand.mean()
            c_std = cand.std() + 1e-8
            c_norm = (cand - c_mean) / c_std
            # ä½¿ç”¨ç‚¹ç§¯è®¡ç®—ç›¸å…³æ€§ï¼ˆæ¯”corrcoefå¿«ï¼‰
            corr = np.dot(q_norm, c_norm) / window
            if np.isnan(corr):
                corr = 0.0
            sim = (corr + 1.0) / 2.0
            date_str = df_f.index[j - 1].strftime("%Y%m%d")
            candidates.append({
                "symbol": str(symbol).zfill(6),
                "date": date_str,
                "score": float(sim),
                "correlation": float(corr)
            })
        candidates.sort(key=lambda x: x["score"], reverse=True)
        return candidates[:top_k]
    except Exception:
        return []


def _plot_ic_curve(rolling_ic, ic_result):
    """ç»˜åˆ¶ICæ›²çº¿"""
    import streamlit as st

    st.markdown("#### IC åˆ†æ")
    if rolling_ic.empty:
        st.write("IC æ•°æ®ä¸è¶³")
        return

    summary = ic_result.get("summary", {})
    mean_ic = summary.get("mean_ic", 0.0)
    std_ic = summary.get("std_ic", 0.0)
    ic_ir = summary.get("ir", 0.0)
    positive_ratio = summary.get("positive_ratio", 0.0)
    half_life = summary.get("half_life", None)
    stability = summary.get("stability_score", None)

    # ä¿®æ­£é€»è¾‘ï¼šICä¸ºè´Ÿä¸ä¸€å®šæ— æ•ˆï¼Œå¯èƒ½æ˜¯åå‘æŒ‡æ ‡
    if abs(mean_ic) > 0.05:
        ic_status = "æ˜¾è‘—" + ("(æ­£å‘)" if mean_ic > 0 else "(åå‘)")
        ic_color = "normal" if mean_ic > 0 else "inverse"  # è´Ÿå€¼ç»™çº¢è‰²/åè‰²æç¤º
    elif abs(mean_ic) > 0.02:
        ic_status = "å¾®å¼±"
        ic_color = "off"
    else:
        ic_status = "æ— æ•ˆ"
        ic_color = "off"

    col1, col2, col3, col4, col5, col6 = st.columns(6)
    col1.metric("å¹³å‡IC", f"{mean_ic:.4f}", delta=ic_status, delta_color=ic_color)
    col2.metric("ICæ ‡å‡†å·®", f"{std_ic:.4f}")
    col3.metric("ICIR", f"{ic_ir:.2f}", delta="ä¼˜ç§€" if abs(ic_ir) > 1.0 else "ä¸€èˆ¬")
    col4.metric("æ­£ICæ¯”ä¾‹", f"{positive_ratio*100:.1f}%",
               delta="è‰¯å¥½" if positive_ratio > 0.6 else "ä¸€èˆ¬")
    col5.metric("IC Half-Life", f"{half_life:.1f}" if half_life is not None else "N/A")
    col6.metric("ç¨³å®šæ€§è¯„åˆ†", f"{float(stability):.2f}" if stability is not None else "N/A")

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=rolling_ic.index,
        y=rolling_ic.values,
        name="Rolling IC",
        marker_color=['red' if x >= 0 else 'green' for x in rolling_ic.values]
    ))
    # ç´¯ç§¯ICæ›²çº¿
    cum_ic = rolling_ic.cumsum()
    fig.add_trace(go.Scatter(
        x=rolling_ic.index,
        y=cum_ic.values,
        name="Cumulative IC",
        yaxis="y2",
        line=dict(color='blue', width=2)
    ))

    fig.update_layout(
        title="æ»šåŠ¨ICä¸ç´¯ç§¯IC",
        height=300,
        yaxis=dict(title="Rolling IC"),
        yaxis2=dict(title="Cumulative IC", overlaying="y", side="right"),
        showlegend=True
    )
    st.plotly_chart(fig, use_container_width=True)

    with st.expander("â„¹ï¸ å› å­åˆ†æè¯´æ˜ä¸æŒ‡æ ‡è§£è¯»", expanded=False):
        st.markdown(r"""
        **1. æ ¸å¿ƒæ¦‚å¿µ**
        - **å› å­å®šä¹‰**: Kçº¿å­¦ä¹ å› å­ = ç›¸ä¼¼åº¦åŠ æƒçš„æ··åˆèƒœç‡ï¼ˆä½œä¸ºæœŸæœ›æ”¶ç›Šä»£ç†ï¼‰
        - **IC (Information Coefficient)**: å› å­å€¼ä¸æœªæ¥æ”¶ç›Šç‡çš„ç›¸å…³ç³»æ•°ã€‚åæ˜ å› å­é¢„æµ‹èƒ½åŠ›ã€‚
        - **Rolling IC**: æ»šåŠ¨çª—å£ä¸‹çš„ICå€¼ï¼Œç”¨äºè§‚å¯Ÿå› å­éšæ—¶é—´çš„ç¨³å®šæ€§ã€‚

        **2. æŒ‡æ ‡è§£è¯»æ ‡å‡†**
        - **å¹³å‡IC**:
          - `> 0.05`: æ˜¾è‘—æ­£å‘ï¼ˆå› å­åˆ†è¶Šé«˜ï¼Œæœªæ¥æ¶¨å¹…è¶Šå¤§ï¼‰
          - `< -0.05`: æ˜¾è‘—åå‘ï¼ˆå¯ä½œä¸ºåå‘æŒ‡æ ‡ä½¿ç”¨ï¼‰
          - `abs(IC) < 0.02`: é¢„æµ‹èƒ½åŠ›å¾®å¼±
        - **ICIR (IC/Std)**: è¡¡é‡å› å­ç¨³å®šæ€§ï¼ˆICå‡å€¼/ICæ ‡å‡†å·®ï¼‰ã€‚ç»å¯¹å€¼ `> 1.0` ä¸ºä¼˜ç§€ã€‚
        - **æ­£ICæ¯”ä¾‹**: æ»šåŠ¨IC > 0 çš„æ—¶é—´å æ¯”ï¼Œè¶Šé«˜è¶Šå¥½ã€‚
        - **Half-Life (åŠè¡°æœŸ)**: å› å­é¢„æµ‹èƒ½åŠ›è¡°å‡ä¸€åŠæ‰€éœ€å¤©æ•°ã€‚è¶Šé•¿è¶Šé€‚åˆä¸­é•¿çº¿ã€‚

        **3. è¿›é˜¶åˆ†æ**
        - **Regimeåˆ†æ**: åœ¨ä¸åŒå¸‚åœºçŠ¶æ€ï¼ˆç‰›/ç†Š/éœ‡è¡ï¼‰ä¸‹çš„å› å­è¡¨ç°å·®å¼‚ã€‚
        - **å› å­è¡°å‡**: è§‚å¯Ÿè¿‘æœŸICæ˜¯å¦æ˜¾è‘—å¼±äºæ—©æœŸICï¼Œæç¤ºå¤±æ•ˆé£é™©ã€‚
        - **å¤±æ•ˆæ£€æµ‹**: ç»¼åˆICè¡°å‡ã€æ‹¥æŒ¤åº¦ç­‰ç»´åº¦åˆ¤æ–­å› å­æ˜¯å¦å¤±æ•ˆã€‚
        """)


def _plot_ic_horizon_matrix(multi_ic: dict):
    """å¤šæŒæœ‰æœŸICçŸ©é˜µ"""
    import streamlit as st
    st.subheader("å¤šæŒæœ‰æœŸICçŸ©é˜µï¼ˆICè¡°å‡ï¼‰")
    matrix = multi_ic.get("ic_matrix")
    if matrix is None or matrix.empty:
        st.caption("ICçŸ©é˜µæ•°æ®ä¸è¶³")
        return
    st.dataframe(matrix, use_container_width=True, hide_index=True)

    try:
        fig = go.Figure(data=go.Heatmap(
            z=matrix[["ic_mean", "ic_ir", "half_life"]].values,
            x=["ICå‡å€¼", "ICIR", "Half-Life"],
            y=matrix["horizon"].astype(str).tolist(),
            colorscale="RdBu"
        ))
        fig.update_layout(height=280, title="ICçŸ©é˜µçƒ­å›¾ï¼ˆä¸åŒæŒæœ‰æœŸï¼‰")
        st.plotly_chart(fig, use_container_width=True)
    except Exception:
        pass


def _plot_sharpe_curve(ic_result):
    """ç»˜åˆ¶æ»šåŠ¨Sharpe"""
    import streamlit as st
    sharpe_series = ic_result.get("sharpe_series", pd.Series(dtype=float))

    if sharpe_series.empty:
        return

    st.subheader("Rolling Sharpe åˆ†æ")
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=sharpe_series.index,
        y=sharpe_series.values,
        name="Rolling Sharpe",
        line=dict(color='orange')
    ))

    mean_sharpe = sharpe_series.mean()
    fig.add_hline(y=0, line_dash="dash", line_color="gray")
    fig.update_layout(height=300)
    st.plotly_chart(fig, use_container_width=True)
    st.caption(f"Rolling Sharpeå‡å€¼: {mean_sharpe:.3f}")


def _plot_regime_distribution(df):
    """Regimeåˆ†å¸ƒ"""
    pass


def _plot_decay_analysis(rolling_ic, decay_result=None):
    """å› å­è¡°å‡åˆ†æ"""
    import streamlit as st

    st.subheader("å› å­è¡°å‡åˆ†æ")
    decay_window = min(60, len(rolling_ic))
    if decay_window < 10:
        return

    recent_ic = rolling_ic.tail(decay_window).mean()
    earlier_ic = rolling_ic.head(decay_window).mean() if len(rolling_ic) > decay_window else recent_ic
    decay_rate = (recent_ic - earlier_ic) / abs(earlier_ic) * 100 if earlier_ic != 0 else 0

    col1, col2 = st.columns(2)
    col1.metric("æ—©æœŸICå‡å€¼", f"{earlier_ic:.4f}")
    col2.metric("è¿‘æœŸICå‡å€¼", f"{recent_ic:.4f}", delta=f"{decay_rate:.1f}%",
               delta_color="inverse" if decay_rate < 0 else "normal")

    # æ‹ç‚¹ä¿¡æ¯
    if decay_result:
        cps = decay_result.get("change_points", [])
        if cps:
            st.caption(f"æ£€æµ‹åˆ°æ‹ç‚¹: {', '.join([str(c) for c in cps[-3:]])}")


def _detect_invalidation(factor_values, returns):
    """å› å­å¤±æ•ˆæ£€æµ‹"""
    pass


def _safe_date_str(dt):
    try:
        return dt.strftime("%Y%m%d")
    except Exception:
        return str(dt)
